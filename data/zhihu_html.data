<!doctype html>
<html lang="zh" data-hairline="true" class="itcauecng" data-theme="light"><head><meta charSet="utf-8"/><title data-rh="true">模型并行训练：为什么要用Megatron，DeepSpeed不够用吗？ - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-rh="true" name="keywords" content="模型并行,LLM（大型语言模型）"/><meta data-rh="true" name="description" content="背景最近工作要解答的问题：为什么要用Megatron，DeepSpeed不够用吗？ 回答：因为领导要用（划去，bushi）。 领导：回去好好调研一下，下周给大领导汇报 1.Megatron相比于DeepSpeed的特性我们看一下BLOOM中对megat…"/><meta data-rh="true" property="og:title" content="模型并行训练：为什么要用Megatron，DeepSpeed不够用吗？"/><meta data-rh="true" property="og:url" content="https://zhuanlan.zhihu.com/p/670958880"/><meta data-rh="true" property="og:description" content="背景最近工作要解答的问题：为什么要用Megatron，DeepSpeed不够用吗？ 回答：因为领导要用（划去，bushi）。 领导：回去好好调研一下，下周给大领导汇报 1.Megatron相比于DeepSpeed的特性我们看一下BLOOM中对megat…"/><meta data-rh="true" property="og:image" content=""/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="og:site_name" content="知乎专栏"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.81060cab.png" sizes="152x152"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.d5793cac.png" sizes="120x120"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7abf3393.png" sizes="76x76"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.362a8eac.png" sizes="60x60"/><link crossorigin="" rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/heifetz/favicon.ico"/><link crossorigin="" rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/heifetz/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pica.zhimg.com"/><link rel="dns-prefetch" href="//picx.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><link rel="dns-prefetch" href="//static.zhihu.com"/><style data-emotion-css="9mvwt1">:root{--zhc-padding-horizontal:20px;--zhc-padding-vertical:16px;--zhc-notification-top:75px;--app-padding:16px;--app-header-height:52px;--app-max-width:640px;--app-width:1000px;--app-font-size:15px;}</style><script nonce="ba2b6cde-fc34-42c9-a23e-8210c5ca27e0" data-web-reporter-config="{&quot;platform&quot;:&quot;web&quot;,&quot;project&quot;:&quot;heifetz&quot;}">!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?t(exports):"function"==typeof define&&define.amd?define(["exports"],t):t((e=e||self).webReporter={})}(this,function(e){"use strict";var t={},n=!1,o=function(){var e,o,r,a,i;return n||(e=document.querySelector("script[data-web-reporter-config]"),o=e&&e.dataset.webReporterConfig||"{}",r=JSON.parse(o),a=r.platform,i=r.project,t={platform:a,project:i},n=!0),t};function r(e){return a(function(){return localStorage.getItem(e)})()}function a(e){return function(){try{return e.apply(void 0,arguments)}catch(e){}}}var i=a(function(e,t){var n={platform:"web",project:o().project,clientTimestamp:+new Date};!function(e,t,n){"1"===r("weber:logenabled")&&console.log("[web-reporter]%o",{type:e,base:t,data:n})}(e,n,t),function(e,t){var n=btoa(JSON.stringify(t));if("undefined"!=typeof Blob&&window.navigator&&window.navigator.sendBeacon){var o=new Blob([n],{type:"text/plain"});navigator.sendBeacon(e,o)}else{var r=new XMLHttpRequest;r.open("POST",e),r.withCredentials=!1,r.setRequestHeader("Content-Type","text/plain;charset=UTF-8"),r.send(n)}}(r("weber:api")||"https://apm.zhihu.com/collector/web_json",{type:e,base:n,data:t})});e.report=i,Object.defineProperty(e,"__esModule",{value:!0})});
</script><link href="https://static.zhihu.com/heifetz/1907.216a26f4.3a30d0c778e087df9648.css" crossorigin="" rel="stylesheet"/><link href="https://static.zhihu.com/heifetz/column.216a26f4.4baf481e21666ae89508.css" crossorigin="" rel="stylesheet"/><script nonce="ba2b6cde-fc34-42c9-a23e-8210c5ca27e0">!function(){"use strict";!function(e,n){var r=[];function t(e){return function(){r.push([e,arguments])}}n.Raven={captureException:t("captureException"),captureMessage:t("captureMessage"),captureBreadcrumb:t("captureBreadcrumb")};var a,o,c,i,s,u="undefined"!=typeof DOMError;function d(e){var n=e instanceof Error||e instanceof ErrorEvent||u&&e instanceof DOMError||e instanceof DOMException;Raven.captureException(n?e:new Error(e.message||e.reason))}n.addEventListener("unhandledrejection",d),n.addEventListener("error",d,!0),a=e.src,o=e,c=function(){r.forEach(function(e){var n;(n=Raven)[e[0]].apply(n,e[1])}),n.removeEventListener("unhandledrejection",d),n.removeEventListener("error",d,!0)},i=document.head||document.getElementsByTagName("head")[0],(s=document.createElement("script")).crossOrigin=o.crossOrigin,s.dataset.sentryConfig=o["data-sentry-config"],s.onload=c,s.src=a,i.appendChild(s)}({"defer":true,"crossOrigin":"anonymous","src":"https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js","data-sentry-config":"{\"dsn\":\"https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224\",\"sampleRate\":0.1,\"release\":\"1469-87f58f34\",\"ignoreErrorNames\":[\"NetworkError\",\"SecurityError\"],\"ignoreErrorsPreset\":\"ReactApp\",\"tags\":{\"app_name\":\"heifetz\"}}"},window)}();
</script></head><body class="WhiteBg-body PostIndex-body"><div id="root"><div class="App"><style data-emotion-css="55n9hh">.css-55n9hh{position:fixed;top:0;right:0;left:0;z-index:101;display:none;height:2px;pointer-events:none;background:#1772F6;-webkit-transform:translateX(-100%);-ms-transform:translateX(-100%);transform:translateX(-100%);}</style><div class="LoadingBar  css-55n9hh"></div><div><span style="position:absolute;top:-10000px;left:-10000px" role="log" aria-live="assertive"></span></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;流逝&quot;,&quot;itemId&quot;:670958880,&quot;title&quot;:&quot;模型并行训练：为什么要用Megatron，DeepSpeed不够用吗？&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><style data-emotion-css="1l12z7y">.css-1l12z7y{box-shadow:0px 16px 32px rgba(0,0,0,0.04);}</style><div class="Sticky ColumnPageHeader css-1l12z7y"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><style data-emotion-css="1hlrcxk">.css-1hlrcxk{-webkit-transition-property:fill;transition-property:fill;-webkit-transition-duration:0.25s;transition-duration:0.25s;-webkit-transition-timing-function:ease-in;transition-timing-function:ease-in;}</style><svg viewBox="0 0 64 30" fill="#1772F6" width="64" height="30" class="css-1hlrcxk"><path d="M29.05 4.582H16.733V25.94h3.018l.403 2.572 4.081-2.572h4.815V4.582zm-5.207 18.69l-2.396 1.509-.235-1.508h-1.724V7.233h6.78v16.04h-2.425zM14.46 14.191H9.982c0-.471.033-.954.039-1.458v-5.5h5.106V5.935a1.352 1.352 0 0 0-.404-.957 1.378 1.378 0 0 0-.968-.396H5.783c.028-.088.056-.177.084-.255.274-.82 1.153-3.326 1.153-3.326a4.262 4.262 0 0 0-2.413.698c-.57.4-.912.682-1.371 1.946-.532 1.453-.997 2.856-1.31 3.693C1.444 8.674.28 11.025.28 11.025a5.85 5.85 0 0 0 2.52-.61c1.119-.593 1.679-1.502 2.054-2.883l.09-.3h2.334v5.5c0 .5-.045.982-.073 1.46h-4.12c-.71 0-1.39.278-1.893.775a2.638 2.638 0 0 0-.783 1.874h6.527a17.717 17.717 0 0 1-.778 3.649 16.796 16.796 0 0 1-3.012 5.273A33.104 33.104 0 0 1 0 28.74s3.13 1.175 5.425-.954c1.388-1.292 2.631-3.814 3.23-5.727a28.09 28.09 0 0 0 1.12-5.229h5.967v-1.37a1.254 1.254 0 0 0-.373-.899 1.279 1.279 0 0 0-.909-.37z"></path><path d="M11.27 19.675l-2.312 1.491 5.038 7.458a6.905 6.905 0 0 0 .672-2.218 3.15 3.15 0 0 0-.28-2.168l-3.118-4.563zM51.449 15.195V5.842c4.181-.205 7.988-.405 9.438-.483l.851-.05c.387-.399.885-2.395.689-3.021-.073-.25-.213-.666-.638-.555a33.279 33.279 0 0 1-4.277.727c-2.766.321-3.97.404-7.804.682-6.718.487-12.709.72-12.709.72a2.518 2.518 0 0 0 .788 1.834 2.567 2.567 0 0 0 1.883.706c2.278-.095 5.598-.25 8.996-.41v9.203h-12.78c0 .703.281 1.377.783 1.874a2.69 2.69 0 0 0 1.892.777h10.105v7.075c0 .887-.464 1.192-1.231 1.214h-3.92a4.15 4.15 0 0 0 .837 1.544 4.2 4.2 0 0 0 1.403 1.067 6.215 6.215 0 0 0 2.71.277c1.36-.066 2.967-.826 2.967-3.57v-7.607h11.28c.342 0 .67-.135.91-.374.242-.239.378-.563.378-.902v-1.375H51.449z"></path><path d="M42.614 8.873a2.304 2.304 0 0 0-1.508-.926 2.334 2.334 0 0 0-1.727.405l-.376.272 4.255 5.85 2.24-1.62-2.884-3.98zM57.35 8.68l-3.125 4.097 2.24 1.663 4.517-5.927-.375-.277a2.32 2.32 0 0 0-1.722-.452 2.327 2.327 0 0 0-1.536.896z"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="//www.zhihu.com/column/c_1363448145687584768">关于算法工作的一些记录</a></div></div><div class="ColumnPageHeader-Button"><div class="Popover"><button title="更多" id="null-toggle" aria-haspopup="true" aria-expanded="false" type="button" class="Button ColumnPageHeader-MenuToggler FEfUrdfMIKpQDJDqkjte Button--plain fEPKGkUK5jyc4fUuT0QP"><svg width="24" height="24" viewBox="0 0 24 24" class="Zi Zi--Dots" fill="currentColor"><path d="M6 10.5a1.5 1.5 0 1 0 0 3 1.5 1.5 0 0 0 0-3ZM10.5 12a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0ZM16.5 12a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Z"></path></svg></button></div><button type="button" class="Button ColumnPageHeader-WriteButton FEfUrdfMIKpQDJDqkjte Button--blue JmYzaky7MEPMFcJDLNMG"><svg width="24" height="24" viewBox="0 0 24 24" class="Zi Zi--EditSurround" fill="currentColor"><path d="M4.352 6.804A2.554 2.554 0 0 1 6.905 4.25h6.072a.875.875 0 0 0 0-1.75H6.905a4.304 4.304 0 0 0-4.303 4.304v10.142a4.304 4.304 0 0 0 4.303 4.304h10.143a4.304 4.304 0 0 0 4.304-4.304v-6.071a.875.875 0 0 0-1.75 0v6.071a2.554 2.554 0 0 1-2.554 2.554H6.905a2.554 2.554 0 0 1-2.553-2.554V6.804Z"></path><path d="M20.595 4.731a.875.875 0 1 0-1.237-1.237l-7.763 7.762a.875.875 0 1 0 1.238 1.238l7.762-7.763Z"></path></svg>写文章</button></div></div><div class="ColumnPageHeader-profile"><button type="button" class="Button AppHeader-profileEntry FEfUrdfMIKpQDJDqkjte Button--plain fEPKGkUK5jyc4fUuT0QP"><style data-emotion-css="icip60">.css-icip60{border-radius:2px;}</style><style data-emotion-css="fnnb9l">.css-fnnb9l{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#ffffff;width:30px;height:30px;border-radius:2px;}</style><img class="Avatar AppHeader-profileAvatar css-fnnb9l" src="https://pic1.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpeg" srcSet="https://pic1.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpeg 2x" alt="点击打开undefined的主页"/></button></div></div></div></div><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">模型并行训练：为什么要用Megatron，DeepSpeed不够用吗？</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><div class="AuthorInfo"><meta itemProp="name" content="流逝"/><meta itemProp="image" content="https://picx.zhimg.com/3eed5e16176fbabd210a0bfa49ee68e5_l.jpg?source=172ae18b"/><meta itemProp="url" content="https://www.zhihu.com/people/lu-kai-14-46"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><a href="//www.zhihu.com/people/lu-kai-14-46" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User"><style data-emotion-css="uodor8">.css-uodor8{border-radius:50%;}</style><style data-emotion-css="1syywx2">.css-1syywx2{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#ffffff;width:38px;height:38px;border-radius:50%;}</style><img class="Avatar AuthorInfo-avatar css-1syywx2" src="https://picx.zhimg.com/3eed5e16176fbabd210a0bfa49ee68e5_l.jpg?source=172ae18b" srcSet="https://picx.zhimg.com/3eed5e16176fbabd210a0bfa49ee68e5_l.jpg?source=172ae18b 2x" alt="流逝"/></a></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><a href="//www.zhihu.com/people/lu-kai-14-46" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User">流逝</a><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"></div></div></div></div></div><button type="button" class="Button FollowButton FEfUrdfMIKpQDJDqkjte Button--primary Button--blue epMJl0lFQuYbC7jrwr_o JmYzaky7MEPMFcJDLNMG"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Plus FollowButton-icon" fill="currentColor"><path fill-rule="evenodd" d="M13.25 3.25a1.25 1.25 0 1 0-2.5 0v7.5h-7.5a1.25 1.25 0 1 0 0 2.5h7.5v7.5a1.25 1.25 0 1 0 2.5 0v-7.5h7.5a1.25 1.25 0 0 0 0-2.5h-7.5v-7.5Z" clip-rule="evenodd"></path></svg></span>关注他</button></div><style data-emotion-css="z4ujak">.css-z4ujak{color:#8491a5;}</style><span class="css-z4ujak"></span></header><div class="Post-RichTextContainer"><style data-emotion-css="1od93p9">.css-1od93p9{margin-top:16px;position:relative;}</style><div class="css-1od93p9"><style data-emotion-css="376mun">.css-376mun{position:relative;display:inline;}</style><div class="css-376mun"><style data-emotion-css="1dlndns">.css-1dlndns{position:absolute;left:NaNpx;top:0;}</style><style data-emotion-css="ldd79s">.css-ldd79s{box-sizing:border-box;margin:0;min-width:0;position:absolute;left:NaNpx;top:0;}</style><div class="css-ldd79s"></div><style data-emotion-css="dg64xe">.css-dg64xe .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(248,248,250,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-dg64xe .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-dg64xe .FileLinkCard-info{margin-left:12px;}.css-dg64xe .FileLinkCard-name{color:#191B1F;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-dg64xe .FileLinkCard-meta{color:#9196a1;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-dg64xe .FileLinkCard-source{white-space:pre;}.css-dg64xe img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}.css-dg64xe img.content_image[data-size="normal"],.css-dg64xe img.origin_image[data-size="normal"]{width:100%;max-width:100%;}.css-dg64xe img.content_image[data-size="small"],.css-dg64xe img.origin_image[data-size="small"]{width:320px;max-width:100%;}</style><style data-emotion-css="1vqsdx1">.css-1vqsdx1 .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#f8f8fa;}.css-1vqsdx1 .LinkCard.new,.css-1vqsdx1 .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1vqsdx1 .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1vqsdx1 .LinkCard.new .LinkCard-contents .loading{height:14px;background:#ebeced;border-radius:7px;}.css-1vqsdx1 .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1vqsdx1 .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#191B1F;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1vqsdx1 .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1vqsdx1 .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1vqsdx1 .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1vqsdx1 .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1vqsdx1 .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#9196a1;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1vqsdx1 .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#373a40;}.css-1vqsdx1 .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#9196a1;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1vqsdx1 .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1vqsdx1 .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(196,199,206,0.3);}.css-1vqsdx1 .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1vqsdx1 .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1vqsdx1 .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#ebeced;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1vqsdx1 .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#ebeced;color:#c4c7ce;}.css-1vqsdx1 .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#9196a1;}.css-1vqsdx1 .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1vqsdx1 .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1vqsdx1 .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#373a40;}.css-1vqsdx1 .LinkCard.new .LinkCard-richText .text{color:#373a40;}.css-1vqsdx1 .LinkCard.new .LinkCard-richText .bold{font-weight:600;}.css-1vqsdx1 .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1vqsdx1 .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1vqsdx1 .LinkCard.old,.css-1vqsdx1 .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1vqsdx1 .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(248,248,250,0.88);color:#c4c7ce;}.css-1vqsdx1 .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#ebeced;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1vqsdx1 .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1vqsdx1 .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1vqsdx1 .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#ebeced;}.css-1vqsdx1 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1vqsdx1 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}</style><style data-emotion-css="yxro2d">.css-yxro2d .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-yxro2d .LinkCard.old,.css-yxro2d .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-yxro2d .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(248,248,250,0.88);color:#c4c7ce;}.css-yxro2d .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#ebeced;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-yxro2d .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-yxro2d .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-yxro2d .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#ebeced;}.css-yxro2d .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-yxro2d .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-yxro2d .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#f8f8fa;}.css-yxro2d .LinkCard.new,.css-yxro2d .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-yxro2d .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-yxro2d .LinkCard.new .LinkCard-contents .loading{height:14px;background:#ebeced;border-radius:7px;}.css-yxro2d .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-yxro2d .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#191B1F;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-yxro2d .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-yxro2d .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-yxro2d .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-yxro2d .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-yxro2d .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#9196a1;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-yxro2d .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#373a40;}.css-yxro2d .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#9196a1;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-yxro2d .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-yxro2d .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(196,199,206,0.3);}.css-yxro2d .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-yxro2d .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-yxro2d .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#ebeced;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-yxro2d .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#ebeced;color:#c4c7ce;}.css-yxro2d .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#9196a1;}.css-yxro2d .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-yxro2d .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-yxro2d .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#373a40;}.css-yxro2d .LinkCard.new .LinkCard-richText .text{color:#373a40;}.css-yxro2d .LinkCard.new .LinkCard-richText .bold{font-weight:600;}.css-yxro2d .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-yxro2d .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(248,248,250,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-yxro2d .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-yxro2d .FileLinkCard-info{margin-left:12px;}.css-yxro2d .FileLinkCard-name{color:#191B1F;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-yxro2d .FileLinkCard-meta{color:#9196a1;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-yxro2d .FileLinkCard-source{white-space:pre;}.css-yxro2d img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}.css-yxro2d img.content_image[data-size="normal"],.css-yxro2d img.origin_image[data-size="normal"]{width:100%;max-width:100%;}.css-yxro2d img.content_image[data-size="small"],.css-yxro2d img.origin_image[data-size="small"]{width:320px;max-width:100%;}</style><style data-emotion-css="1ygg4xu animation-1yvu044">.css-1ygg4xu{word-break:break-word;line-height:1.6;}.css-1ygg4xu > [data-first-child]{margin-top:0;}.css-1ygg4xu > :last-child{margin-bottom:0;}.css-1ygg4xu h1,.css-1ygg4xu h2{clear:left;margin-top:calc((1.4em * 2) / 1.2);margin-bottom:calc(1.4em / 1.2);font-size:1.2em;line-height:1.5;font-weight:600;}.css-1ygg4xu h3,.css-1ygg4xu h4,.css-1ygg4xu h5,.css-1ygg4xu h6{clear:left;margin-top:calc((1.4em * 1.5) / 1.1);margin-bottom:calc(1.4em / 1.1);font-size:1.1em;line-height:1.5;font-weight:600;}.css-1ygg4xu u{-webkit-text-decoration:none;text-decoration:none;border-bottom:1px solid #373a40;}.css-1ygg4xu b{font-weight:600;}.css-1ygg4xu sup{font-size:0.8em;}.css-1ygg4xu sup[data-draft-type='reference']{color:#09408e;}.css-1ygg4xu a:focus{outline:none;-webkit-transition:box-shadow 0.3s;transition:box-shadow 0.3s;}html[data-focus-visible] .css-1ygg4xu a:focus{box-shadow:0 0 0 2px #ffffff,0 0 0 4px rgba(23,114,246,0.3);}.css-1ygg4xu a.ztext-link,.css-1ygg4xu a.internal,.css-1ygg4xu a.external{-webkit-text-decoration:none;text-decoration:none;cursor:pointer;border-bottom:1px solid #81858f;}.css-1ygg4xu a.ztext-link:hover,.css-1ygg4xu a.internal:hover,.css-1ygg4xu a.external:hover{color:#09408e;border-bottom:1px solid #09408e;}.css-1ygg4xu a.ztext-link > .ellipsis::after,.css-1ygg4xu a.internal > .ellipsis::after,.css-1ygg4xu a.external > .ellipsis::after{content:'...';}.css-1ygg4xu a.ztext-link > .invisible,.css-1ygg4xu a.internal > .invisible,.css-1ygg4xu a.external > .invisible{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;}.css-1ygg4xu a.ztext-link u,.css-1ygg4xu a.internal u,.css-1ygg4xu a.external u{border:none;}.css-1ygg4xu a.member_mention{color:#09408e;}.css-1ygg4xu a.member_mention:hover{border-bottom:1px solid #09408e;}.css-1ygg4xu a.UserLink-link{color:#09408e;}.css-1ygg4xu a.UserLink-link:hover{border-bottom:1px solid #09408e;}.css-1ygg4xu p{margin:1.4em 0;}.css-1ygg4xu p.ztext-empty-paragraph{margin:calc((2.8em- (1.4em * 2 + 1.6em)) / 2) 0;}.css-1ygg4xu p.ztext-empty-paragraph + .ztext-empty-paragraph{margin:1.4em 0;}.css-1ygg4xu hr{margin:4em auto;width:240px;max-width:100%;border:none;border-top:1px solid #c4c7ce;}.css-1ygg4xu img[eeimg]{max-width:100%;vertical-align:middle;}.css-1ygg4xu img[eeimg="1"]{margin:0 3px;max-width:calc(100% - 6px);display:inline-block;}.css-1ygg4xu img[eeimg="2"]{margin:1.4em auto;display:block;}.css-1ygg4xu blockquote{margin:1.4em 0;padding-left:1em;color:#535861;border-left:3px solid #c4c7ce;}.css-1ygg4xu ol,.css-1ygg4xu ul{margin:1.4em 0;padding:0;width:100%;}.css-1ygg4xu ol ol,.css-1ygg4xu ul ol,.css-1ygg4xu ol ul,.css-1ygg4xu ul ul{margin:0;}.css-1ygg4xu ol li::before,.css-1ygg4xu ul li::before{width:1em;}.css-1ygg4xu ol > ol,.css-1ygg4xu ul > ol,.css-1ygg4xu ol > ul,.css-1ygg4xu ul > ul{padding-left:1em;box-sizing:border-box;}.css-1ygg4xu ul>li{display:table;width:100%;list-style:none;}.css-1ygg4xu ul>li::before{display:table-cell;content:'•  ';white-space:pre;}.css-1ygg4xu ol{counter-reset:ol;}.css-1ygg4xu ol > li{display:table;width:100%;list-style:none;}.css-1ygg4xu ol > li::before{display:table-cell;text-align:right;counter-increment:ol;content:counter(ol) '. ';white-space:pre;}.css-1ygg4xu ol ol{counter-reset:ol2;}.css-1ygg4xu ol ol li::before{counter-increment:ol2;content:counter(ol2) '. ';}.css-1ygg4xu ol ol ol{counter-reset:ol3;}.css-1ygg4xu ol ol ol li::before{counter-increment:ol3;content:counter(ol3) '. ';}.css-1ygg4xu ol ol ol ol{counter-reset:ol4;}.css-1ygg4xu ol ol ol ol li::before{counter-increment:ol4;content:counter(ol4) '. ';}.css-1ygg4xu figure{margin:1.4em 0;}.css-1ygg4xu figure .content_image,.css-1ygg4xu figure .origin_image{margin:0 auto;}.css-1ygg4xu figure figcaption{margin-top:calc(0.6em / 0.9);padding:0 1em;font-size:0.9em;line-height:1.5;text-align:center;color:#9196a1;}.css-1ygg4xu figure + figure{margin-top:calc(1.4em * 1.6);}.css-1ygg4xu figure[data-size='small'],.css-1ygg4xu figure:not([data-size]) > [data-size='small']{clear:both;}.css-1ygg4xu figure[data-size='left'],.css-1ygg4xu figure:not([data-size]) > [data-size='left']{float:left;margin:0 20px 20px 0;max-width:33%;}.css-1ygg4xu figure[data-size='right'],.css-1ygg4xu figure:not([data-size]) > [data-size='right']{float:right;margin:0 0 20px 20px;max-width:33%;}.css-1ygg4xu figure[data-size='collapse']{margin-bottom:0;}.css-1ygg4xu figure[data-size='collapse'] + figure{margin-top:0;}.css-1ygg4xu .content_image,.css-1ygg4xu .origin_image{display:block;max-width:100%;height:auto;margin:1.4em auto;}.css-1ygg4xu .content_image[data-size='small'],.css-1ygg4xu .origin_image[data-size='small']{max-width:40%;}.css-1ygg4xu .content_image.zh-lightbox-thumb,.css-1ygg4xu .origin_image.zh-lightbox-thumb{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;}.css-1ygg4xu code{margin:0 2px;padding:3px 4px;border-radius:3px;font-family:Menlo,Monaco,Consolas,'Andale Mono','lucida console','Courier New',monospace;font-size:0.9em;background-color:#f8f8fa;}.css-1ygg4xu pre{margin:1.4em 0;padding:calc(0.8em / 0.9);font-size:0.9em;word-break:initial;word-wrap:initial;white-space:pre;overflow:auto;-webkit-overflow-scrolling:touch;background:#f8f8fa;border-radius:4px;}.css-1ygg4xu pre code{margin:0;padding:0;font-size:inherit;border-radius:0;background-color:inherit;}.css-1ygg4xu li pre{white-space:pre-wrap;}.css-1ygg4xu table[data-draft-type='table']{border-collapse:collapse;font-size:15px;margin:1.4em auto;max-width:100%;table-layout:fixed;text-align:left;width:100%;}.css-1ygg4xu table[data-draft-type='table'][data-size='small']{min-width:260px;width:40%;}.css-1ygg4xu table[data-draft-type='table'][data-row-style='striped'] tr:nth-of-type(2n + 1){background:#f8f8fa;}.css-1ygg4xu table[data-draft-type='table'] td,.css-1ygg4xu table[data-draft-type='table'] th{border:1px solid #c4c7ce;line-height:24px;height:24px;padding:3px 12px;}.css-1ygg4xu table[data-draft-type='table'] th{background:#ebeced;color:#191B1F;font-weight:500;}.css-1ygg4xu .video-box,.css-1ygg4xu .link-box{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;margin:1.4em 0;overflow:auto;white-space:normal;cursor:pointer;border:solid 1px #ebeced;border-radius:4px;}.css-1ygg4xu .lazy[data-lazy-status]{background-color:#f8f8fa;}.css-1ygg4xu .lazy[data-lazy-status="ok"]{background-color:transparent;-webkit-animation:animation-1yvu044 0.5s ease-in;animation:animation-1yvu044 0.5s ease-in;}.css-1ygg4xu .highlight{margin:1em 0;}.css-1ygg4xu .highlight pre{margin:0;}.css-1ygg4xu .highlight .hll{background-color:#f8f8fa;}.css-1ygg4xu .highlight .c{font-style:italic;color:#9196a1;}.css-1ygg4xu .highlight .err{color:#D95350;}.css-1ygg4xu .highlight .k{font-weight:600;}.css-1ygg4xu .highlight .o{font-weight:600;}.css-1ygg4xu .highlight .cm{font-style:italic;color:#9196a1;}.css-1ygg4xu .highlight .cp{font-weight:600;color:#9196a1;}.css-1ygg4xu .highlight .c1{font-style:italic;color:#9196a1;}.css-1ygg4xu .highlight .cs{font-style:italic;font-weight:600;color:#9196a1;}.css-1ygg4xu .highlight .gd{color:#F05159;}.css-1ygg4xu .highlight .ge{font-style:italic;}.css-1ygg4xu .highlight .gr{color:#D95350;}.css-1ygg4xu .highlight .gh{color:#9196a1;}.css-1ygg4xu .highlight .gi{color:#12b370;}.css-1ygg4xu .highlight .go{color:#81858f;}.css-1ygg4xu .highlight .gp{color:#535861;}.css-1ygg4xu .highlight .gs{font-weight:600;}.css-1ygg4xu .highlight .gu{color:#9196a1;}.css-1ygg4xu .highlight .gt{color:#D95350;}.css-1ygg4xu .highlight .kc{font-weight:600;}.css-1ygg4xu .highlight .kd{font-weight:600;}.css-1ygg4xu .highlight .kn{font-weight:600;}.css-1ygg4xu .highlight .kp{font-weight:600;}.css-1ygg4xu .highlight .kr{font-weight:600;}.css-1ygg4xu .highlight .kt{font-weight:600;color:#09408e;}.css-1ygg4xu .highlight .m{color:#1772F6;}.css-1ygg4xu .highlight .s{color:#D95350;}.css-1ygg4xu .highlight .na{color:#1772F6;}.css-1ygg4xu .highlight .nb{color:#1772F6;}.css-1ygg4xu .highlight .nc{font-weight:600;color:#09408e;}.css-1ygg4xu .highlight .no{color:#1772F6;}.css-1ygg4xu .highlight .ni{color:#6A5FF3;}.css-1ygg4xu .highlight .ne{font-weight:600;color:#D95350;}.css-1ygg4xu .highlight .nf{font-weight:600;color:#D95350;}.css-1ygg4xu .highlight .nn{color:#535861;}.css-1ygg4xu .highlight .nt{color:#09408e;}.css-1ygg4xu .highlight .nv{color:#1772F6;}.css-1ygg4xu .highlight .ow{font-weight:600;}.css-1ygg4xu .highlight .w{color:#adb0b7;}.css-1ygg4xu .highlight .mf{color:#1772F6;}.css-1ygg4xu .highlight .mh{color:#1772F6;}.css-1ygg4xu .highlight .mi{color:#1772F6;}.css-1ygg4xu .highlight .mo{color:#1772F6;}.css-1ygg4xu .highlight .sb{color:#D95350;}.css-1ygg4xu .highlight .sc{color:#D95350;}.css-1ygg4xu .highlight .sd{color:#D95350;}.css-1ygg4xu .highlight .s2{color:#D95350;}.css-1ygg4xu .highlight .se{color:#D95350;}.css-1ygg4xu .highlight .sh{color:#D95350;}.css-1ygg4xu .highlight .si{color:#D95350;}.css-1ygg4xu .highlight .sx{color:#D95350;}.css-1ygg4xu .highlight .sr{color:#A5542F;}.css-1ygg4xu .highlight .s1{color:#D95350;}.css-1ygg4xu .highlight .ss{color:#D95350;}.css-1ygg4xu .highlight .bp{color:#9196a1;}.css-1ygg4xu .highlight .vc{color:#1772F6;}.css-1ygg4xu .highlight .vg{color:#1772F6;}.css-1ygg4xu .highlight .vi{color:#1772F6;}.css-1ygg4xu .highlight .il{color:#1772F6;}.css-1ygg4xu .highlight::-webkit-scrollbar{width:6px;height:6px;}.css-1ygg4xu .highlight::-webkit-scrollbar-thumb:horizontal{background-color:rgba(25,27,31,0.5);border-radius:6px;}.css-1ygg4xu .highlight::-webkit-scrollbar-thumb:horizontal:hover{background-color:rgba(25,27,31,0.6);}.css-1ygg4xu .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1ygg4xu .LinkCard.old,.css-1ygg4xu .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1ygg4xu .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(248,248,250,0.88);color:#c4c7ce;}.css-1ygg4xu .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#ebeced;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1ygg4xu .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1ygg4xu .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1ygg4xu .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#ebeced;}.css-1ygg4xu .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1ygg4xu .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-1ygg4xu .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#f8f8fa;}.css-1ygg4xu .LinkCard.new,.css-1ygg4xu .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1ygg4xu .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1ygg4xu .LinkCard.new .LinkCard-contents .loading{height:14px;background:#ebeced;border-radius:7px;}.css-1ygg4xu .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1ygg4xu .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#191B1F;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1ygg4xu .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1ygg4xu .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1ygg4xu .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1ygg4xu .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1ygg4xu .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#9196a1;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1ygg4xu .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#373a40;}.css-1ygg4xu .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#9196a1;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1ygg4xu .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1ygg4xu .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(196,199,206,0.3);}.css-1ygg4xu .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1ygg4xu .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1ygg4xu .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#ebeced;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1ygg4xu .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#ebeced;color:#c4c7ce;}.css-1ygg4xu .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#9196a1;}.css-1ygg4xu .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1ygg4xu .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1ygg4xu .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#373a40;}.css-1ygg4xu .LinkCard.new .LinkCard-richText .text{color:#373a40;}.css-1ygg4xu .LinkCard.new .LinkCard-richText .bold{font-weight:600;}.css-1ygg4xu .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1ygg4xu .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(248,248,250,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-1ygg4xu .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-1ygg4xu .FileLinkCard-info{margin-left:12px;}.css-1ygg4xu .FileLinkCard-name{color:#191B1F;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1ygg4xu .FileLinkCard-meta{color:#9196a1;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-1ygg4xu .FileLinkCard-source{white-space:pre;}.css-1ygg4xu img[data-uncomfortable]{content:url(data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20344.88888888888886%20194%22%3E%3CforeignObject%20width%3D%22344.88888888888886%22%20height%3D%22194%22%3E%0A%20%20%20%20%20%20%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22font-size%3A%2013px%3B%20font-family%3A%20-apple-system%2C%20BlinkMacSystemFont%2C%20Microsoft%20YaHei%2C%20sans-serif%3B%20color%3A%20%23fff%3B%20width%3A100%25%3B%20height%3A194px%3B%22%3E%0A%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%20justify-content%3A%20center%3B%20height%3A%20100%25%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2218%22%20height%3D%2218%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22currentColor%22%3E%3Cpath%20d%3D%22M8%203.65a7%207%200%2000-1.353.128.65.65%200%2011-.25-1.275A8.3%208.3%200%20018%202.35c2.387%200%204.172.954%205.357%202.125C14.511%205.615%2015.15%207.022%2015.15%208c0%20.621-.257%201.391-.699%202.134a7.076%207.076%200%2001-1.403%201.68l.495.46a.65.65%200%2011-.886.951l-.998-.929a.645.645%200%2001-.104-.097L9.73%2010.501a.647.647%200%2001-.29.301%203.15%203.15%200%2001-4.313-4.094.647.647%200%2001.234-.275L3.908%205.08a5.774%205.774%200%2000-1.283%201.522C2.282%207.198%202.15%207.707%202.15%208c0%20.522.41%201.616%201.407%202.6.965.954%202.43%201.75%204.443%201.75.468%200%20.905-.043%201.311-.12a.65.65%200%2001.243%201.277A8.322%208.322%200%20018%2013.65c-2.387%200-4.172-.954-5.357-2.125C1.49%2010.385.85%208.978.85%208c0-.598.238-1.333.648-2.046A7.054%207.054%200%20012.95%204.188l-.547-.509a.65.65%200%2011.886-.951l8.8%208.194a5.793%205.793%200%20001.244-1.453c.372-.624.516-1.163.516-1.469%200-.522-.41-1.616-1.407-2.6-.965-.954-2.43-1.75-4.443-1.75zM6.29%207.296a1.85%201.85%200%20002.534%202.36l-2.535-2.36zM8%204.85a.65.65%200%20100%201.3%201.85%201.85%200%20011.843%201.694.65.65%200%20101.296-.11A3.15%203.15%200%20008%204.85z%22%20fill-rule%3D%22evenodd%22%20clip-rule%3D%22evenodd%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cdiv%20style%3D%22margin%3A%20.6em%200%201.2em%22%3E%E8%AF%A5%E5%9B%BE%E7%89%87%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E9%80%82%3C%2Fdiv%3E%0A%20%20%20%20%20%20%20%20%20%20%3Cbutton%20style%3D%22padding%3A%204px%201em%3B%20font-size%3A%201.1em%3B%20color%3A%20inherit%3B%20background%3A%20none%3B%20border%3A%201px%20solid%20rgba%28255%2C255%2C255%2C.5%29%3B%20border-radius%3A%209999px%3B%22%3E%E7%BB%A7%E7%BB%AD%E6%9F%A5%E7%9C%8B%3C%2Fbutton%3E%0A%20%20%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2FforeignObject%3E%3C%2Fsvg%3E);width:100%;height:194px;background:url(https://pic1.zhimg.com/v2-cf70d0759d787c70091857151c1cad4a.jpeg) no-repeat rgba(191,191,191,0.7);background-size:cover;cursor:pointer!important;}.css-1ygg4xu img.content_image[data-size="normal"],.css-1ygg4xu img.origin_image[data-size="normal"]{width:100%;max-width:100%;}.css-1ygg4xu img.content_image[data-size="small"],.css-1ygg4xu img.origin_image[data-size="small"]{width:320px;max-width:100%;}@-webkit-keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}@keyframes animation-1yvu044{from{opacity:0;}to{opacity:1;}}</style><div class="RichText ztext Post-RichText css-1ygg4xu" options="[object Object]"><h2 data-first-child id="h_670958880_0" data-into-catalog-status="">背景</h2><p data-pid="g9viJcYw">最近工作要解答的问题：为什么要用Megatron，DeepSpeed不够用吗？</p><p data-pid="HjnsNzAm">回答：因为领导要用（划去，bushi）。</p><p data-pid="fLv3dHgo">领导：回去好好调研一下，下周给大领导汇报</p><p class="ztext-empty-paragraph"><br/></p><h2 id="h_670958880_1" data-into-catalog-status="">1.Megatron相比于DeepSpeed的特性</h2><p data-pid="DULPX-K7">我们看一下BLOOM中对megatron+deepspeed的使用。</p><p data-pid="MDOUfcoC"><a href="https://link.zhihu.com/?target=https%3A//github.com/huggingface/blog/blob/main/bloom-megatron-deepspeed.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">The Technology Behind BLOOM Training</a></p><p data-pid="PGTesN5S"><a href="https://link.zhihu.com/?target=https%3A//huggingface.co/blog/zh/bloom-megatron-deepspeed%23datasets" class=" wrap external" target="_blank" rel="nofollow noreferrer">千亿参数开源大模型 BLOOM 背后的技术</a></p><p data-pid="lnlf2til"><a href="https://link.zhihu.com/?target=https%3A//huggingface.co/blog/zh/megatron-training" class=" wrap external" target="_blank" rel="nofollow noreferrer">如何使用 Megatron-LM 训练语言模型</a></p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-3f70e4435d0a7e2d92ea8eca29d82b82_b.jpg" data-caption="" data-size="normal" data-rawwidth="878" data-rawheight="447" class="origin_image zh-lightbox-thumb" width="878" data-original="https://pic3.zhimg.com/v2-3f70e4435d0a7e2d92ea8eca29d82b82_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;878&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="878" data-rawheight="447" class="origin_image zh-lightbox-thumb lazy" width="878" data-original="https://pic3.zhimg.com/v2-3f70e4435d0a7e2d92ea8eca29d82b82_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-3f70e4435d0a7e2d92ea8eca29d82b82_b.jpg" data-original-token="v2-546d0b6cf13ebb000f6c23d7a8ae0e4b"/></figure><p data-pid="xiojnsYy">容易得出，在BLOOM看来，tensor并行、Fused CUDA Kernels 和 DataLoader 是Megatron相对于 DeepSpeed 的三大特点。</p><h3 id="h_670958880_2" data-into-catalog-status="">Tensor并行</h3><p data-pid="Jlr3_heX">比较好理解，具体看Megatron论文，就是把一个神经网络层Tensor切成了多个小的Tensor，每个tensor放在不同的gpu。主要就是列并行、行并行。在transformer里的应用具体体现在MLP、Attention层里。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-6ea73fd9877c26c2e37a0d08fdbf0854_b.jpg" data-size="normal" data-rawwidth="1624" data-rawheight="1320" class="origin_image zh-lightbox-thumb" width="1624" data-original="https://pic1.zhimg.com/v2-6ea73fd9877c26c2e37a0d08fdbf0854_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1624&#39; height=&#39;1320&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1624" data-rawheight="1320" class="origin_image zh-lightbox-thumb lazy" width="1624" data-original="https://pic1.zhimg.com/v2-6ea73fd9877c26c2e37a0d08fdbf0854_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-6ea73fd9877c26c2e37a0d08fdbf0854_b.jpg" data-original-token="v2-559b93c1ffaae85d69bd53b0fadf75db"/><figcaption>Tensor并行：列并行、行并行</figcaption></figure><h3 id="h_670958880_3" data-into-catalog-status="">Fused CUDA Kernels</h3><p data-pid="r5XVaCsf">简单来说，就是nvidia对cuda运算的优化，这部分代码在Megatron代码里都是c/c++。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-be77c1446ba060be9e010bd3fd9b99d4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1334" data-rawheight="564" class="origin_image zh-lightbox-thumb" width="1334" data-original="https://pic1.zhimg.com/v2-be77c1446ba060be9e010bd3fd9b99d4_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1334&#39; height=&#39;564&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1334" data-rawheight="564" class="origin_image zh-lightbox-thumb lazy" width="1334" data-original="https://pic1.zhimg.com/v2-be77c1446ba060be9e010bd3fd9b99d4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-be77c1446ba060be9e010bd3fd9b99d4_b.jpg" data-original-token="v2-5739a9eb93f7460352ca020b4a52d3c2"/></figure><p data-pid="Yg-UDfKE">如图的例子，本来这个计算涉及到三个函数，需要换进换出显存三次。融合后，只需要一次换进换出了。加快了计算速度。</p><p class="ztext-empty-paragraph"><br/></p><h3 id="h_670958880_4" data-into-catalog-status="">DataLoader</h3><p data-pid="-sM-kwvB">通过提前做tokenize、shuffle做成文件，训练时每个epoch根据索引来获取数据。</p><p data-pid="yfmMXhRk">我其实个人觉得这玩意没啥，在之前微调7b模型的时候，数据处理的耗时跟模型训练的耗时跟本没法比。当然有的人觉得能快一点是一点。</p><p class="ztext-empty-paragraph"><br/></p><h2 id="h_670958880_5" data-into-catalog-status="">2.主流大模型中对Megatron的使用</h2><p data-pid="mlxdhr2L">领导，你看人家都用这玩意，咱是不是也得用一下？</p><table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>模型</th><th>机器/显卡</th><th>tensor并行</th><th>pipeline并行</th><th>数据并行</th></tr><tr><td>GLM130B</td><td>96机 8卡 40G A100</td><td>tp=4</td><td>pp=8</td><td>dp=24, zero stage1</td></tr><tr><td>BLOOM</td><td>48机 8卡 80G A100</td><td>tp=4</td><td>pp=12</td><td>dp=8, zero stage1</td></tr><tr><td>OPT</td><td>124机8卡80G A100</td><td>tp=8</td><td>没提</td><td>Fully Sharded Data Parallel，类似于zero stage3</td></tr><tr><td>Baichuan-2</td><td>128机8卡80GA800</td><td>用了，没具体讲</td><td>没提</td><td>zero stage3数据并行</td></tr><tr><td>LLaMA1-65B</td><td>256机8卡 80G</td><td>用了，没具体讲</td><td>用了，没具体讲</td><td>没提到，疑似用了</td></tr></tbody></table><h3 id="h_670958880_6" data-into-catalog-status="">GLM-130B</h3><p data-pid="faTu0Zsr">从论文附录看，GLM-130B尝试过使用DeepSpeed和Megatron，虽然最后的论文正文没提megatron。</p><blockquote data-pid="8IiR5CEk">Major Issues Encountered for Training GLM-130B<br/>2022.2  Debug the 3D pipeline parallel in the newly-released Megatron and DeepSpeed </blockquote><p data-pid="-RrpIE3M">Github issue：</p><blockquote data-pid="8GlNpq0s">Unlike OPT-175B and BLOOM-176B, we use 40G A100 instead of its 80G version, so the GPU memory could be very tight for training. We have tried numerous combinations of parallelism / hidden size / layers and ended up using 4-way tensor and 8-way pipeline parallelism for the best training throughput, approximately 135 TFLOPS / GPU. Adam optimizer with ZeRO stage 1 is used in actual training. At least 40 nodes are required to start training. Using optimizers like Adafactor or 8-bit Adam could further reduce the minimum requirement to 24 nodes, however, we did not use them for best convergence.</blockquote><p data-pid="FIxfHl3E">很有意思的一点是，issue中提到了Adam二阶动量用的显存比较多，只用一阶动量的Adafactor可以明显减少显存使用，但是同样设置下Adam收敛得更好。</p><p data-pid="zrZ9RAOa">很好奇，同样计算量、资源下，Adam换成其他优化器，减少显存，增加训练数据、训练时间，是不是效果会更好一些。毕竟Adam是2014年的产物了，当时不像现在，显存成为了很多人训练大模型的瓶颈。</p><p data-pid="U6sbQi6t">96*8张卡，train了2个月。</p><blockquote data-pid="ck9IW_eE">   pre-trained over 400 billion tokens on a cluster of 96 NVIDIA DGX-A100 (8×40G) GPU nodes between May 6 and July 3, 2022 </blockquote><p data-pid="ftiD3w0N">tp=4，pp=8, dp=24, 数据并行采用zero stage1</p><h3 id="h_670958880_7" data-into-catalog-status="">BLOOM</h3><p data-pid="VxlafGGy">论文原文：</p><blockquote data-pid="F6WNVqf2"> 3.4.2 Framework <br/> BLOOM was trained using Megatron-DeepSpeed20 (Smith et al., 2022), a framework for large-scale distributed training. It consists of two parts: Megatron-LM21 (Shoeybi et al., 2019) provides the Transformer implementation, tensor parallelism, and data loading prim- itives, whereas DeepSpeed22 (Rasley et al., 2020) provides the ZeRO optimizer, model pipelining, and general distributed training components. This framework allows us to train efficiently with 3D parallelism (Narayanan et al., 2021, shown in Figure 6), a fusion of three complementary approaches to distributed training. </blockquote><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-d1d1bd26589af3b7edfaadc8884aa79b_b.jpg" data-size="normal" data-rawwidth="1732" data-rawheight="954" class="origin_image zh-lightbox-thumb" width="1732" data-original="https://pic4.zhimg.com/v2-d1d1bd26589af3b7edfaadc8884aa79b_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1732&#39; height=&#39;954&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1732" data-rawheight="954" class="origin_image zh-lightbox-thumb lazy" width="1732" data-original="https://pic4.zhimg.com/v2-d1d1bd26589af3b7edfaadc8884aa79b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-d1d1bd26589af3b7edfaadc8884aa79b_b.jpg" data-original-token="v2-67bd5a416910a98b278e90252dcfa426"/><figcaption>BLOOM论文中的3D并行</figcaption></figure><blockquote data-pid="EfNyVhjy"> We used ZeRO stage 1, meaning that only the optimizer states are sharded in this manner. <br/> The four components described above are combined together to allow scaling to hundreds of GPUs with extremely high GPU utilization. We were able to achieve 156 TFLOPs in our fastest configuration with A100 GPUs, attaining our objective of half of the theoretical peak performance of 312 TFLOPs (in float32 or bfloat16). </blockquote><p data-pid="raH224Sy">硬件：</p><blockquote data-pid="f5r4DiUB">Training was conducted on 48 nodes, each having 8 NVIDIA A100 80GB GPUs (a total of 384 GPUs); due to possible hardware failures during training, we also maintained a reserve of 4 spare nodes. The nodes were equipped with 2x AMD EPYC 7543 32-Core CPUs and 512 GB of RAM, while the storage was handled by mix of full flash and hard disk drives using a SpectrumScale (GPFS) parallel file system shared between all nodes and users of the supercomputer. 4 NVLink GPU-to- GPU interconnects per node enabled intra-node communications while 4 Omni-Path 100 Gbps links per node, arranged in an enhanced hypercube 8D global topology, were used for inter-node communications. </blockquote><p data-pid="TGIhVFsX">48*8 个80G A100</p><p data-pid="NM8t0Xes">tensor并行数=4，pipeline并行数=12，数据并行数=8，数据并行采用zero stage1。</p><h3 id="h_670958880_8" data-into-catalog-status="">OPT</h3><blockquote data-pid="uAu8pIM-">enabled training OPT-175B on 992 80GB A100 GPUs, reaching 147 TFLOP/s utilization per GPU. </blockquote><p data-pid="j9xg1sFO">应该是992=124*8个 80G A100</p><blockquote data-pid="zYcrvYVj">2.4 Training Efficiency <br/> We trained OPT-175B on 992 80GB A100 GPUs, by utilizing Fully Sharded Data Parallel (Artetxe et al., 2021) with Megatron-LM Tensor Parallelism (Shoeybi et al., 2019). We achieve utilization of up to 147 TFLOP/s per GPU. We keep Adam state in FP32, since we shard it across all hosts, while the model weights remained in FP16. To avoid under- flows, we used dynamic loss scaling, as described in Micikevicius et al. (2017). </blockquote><p class="ztext-empty-paragraph"><br/></p><blockquote data-pid="8B2nKN9s">[2021-11-05] Run 11.0: LETS GO<br/>● Tensor parallel (8x MP)</blockquote><p data-pid="ANUdLgPW">tensor并行数=8。数据并行采用Fully Sharded Data Parallel，这个具体不太懂。8*80G明显放不下175B的模型训练，估计Fully Sharded Data Parallel类似于zero做了模型上的切分。</p><h3 id="h_670958880_9" data-into-catalog-status="">Baichuan-2</h3><blockquote data-pid="wavRIVcW"> efficiently on 1,024 NVIDIA A800 GPUs, achieving a computational efficiency that exceeds 180 TFLOPS.</blockquote><p data-pid="XZ3oN-3J">128*8个</p><blockquote data-pid="PX2MkJWJ">our training framework integrates tensor parallelism (Narayanan et al., 2021) and ZeRO- powered data parallelism (Rajbhandari et al., 2020), where we set tensor parallelism inside each machine and employ ZeRO shared data parallelism for elastic scaling across machines. <br/> <i>Hybrid and hierarchical partition for ZeRO</i>. By partitioning parameters across GPUs, ZeRO3 reduces memory consumption at the expense of additional all-gather communications.  </blockquote><p data-pid="tMynef-7">主要使用了tensor并行 和 zero3数据并行，另外加了一些其他自己搞的方法。</p><h3 id="h_670958880_10" data-into-catalog-status="">GPT3</h3><blockquote data-pid="LnAHKuCr">To train the larger models without running out of memory, we use a mixture of model parallelism within each matrix multiply and model parallelism across the layers of the network. All models were trained on V100 GPU’s on part of a high-bandwidth cluster provided by Microsoft.  </blockquote><p data-pid="6crJd_sp">具体没写啥。</p><h3 id="h_670958880_11" data-into-catalog-status="">LLaMA1-65B</h3><blockquote data-pid="2K8EHVEU">   reduce the memory usage of the model by using model and sequence parallelism, as described by Korthikanti et al. (2022). Moreover, we also over- lap the computation of activations and the commu- nication between GPUs over the network (due to all_reduce operations) as much as possible. <br/> When training a 65B-parameter model, our code processes around 380 tokens/sec/GPU on 2048 A100 GPU with 80GB of RAM.  </blockquote><p data-pid="D3lE-6xQ">256机8卡 80G A100</p><p data-pid="seYyERoC">tensor并行，pipeline并行</p><p class="ztext-empty-paragraph"><br/></p><h2 id="h_670958880_12" data-into-catalog-status="">3.Megatron中tensor并行数、pipeline并行数、数据并行数等各并行参数如何确定取值范围？</h2><p data-pid="mKzBCs-Y">主要参考：<a href="https://link.zhihu.com/?target=https%3A//huggingface.co/docs/transformers/main/en/perf_train_gpu_many" class=" wrap external" target="_blank" rel="nofollow noreferrer">Efficient Training on Multiple GPUs</a></p><p data-pid="d_sDrPxB">这里面讨论的情况比较复杂，我的个人理解和总结如下：</p><p data-pid="_-GJTXa5">基于给定模型、给定输入长度、给定机器的情况下。</p><h3 id="h_670958880_13" data-into-catalog-status="">Tensor并行数</h3><p data-pid="izuhV5VQ">tensor并行无气泡等额外计算；但是同步的数据量大，需要快的网络，因此都是在单个机器上；模型太大，单个层在gpu放不下，也得tensor并行。</p><p data-pid="QoRQtXJu"><b>放得下单层 &lt;= tensor并行数 &lt;= 单机卡数 </b></p><h3 id="h_670958880_14" data-into-catalog-status="">Pipeline并行数</h3><p data-pid="q27LKUFe">pp通信快，适合通信慢模型大到单卡/单机放不下的场景；存在气泡；tensor并行放不下，再用pipeline并行。</p><p data-pid="c-QcdQ44">多大机器能放的下模型参数，这个得具体算一下，计算方法可参考：<a href="https://zhuanlan.zhihu.com/p/624740065" class="internal">回旋托马斯x：分析transformer模型的参数量、计算量、中间激活、KV cache</a></p><p data-pid="UXomjv7s">通过micro batch来减少pipeline并行的气泡，提高训练效率。</p><p data-pid="YSGX0ZNH"><b>放得下模型参数 &lt;= tensor并行数 * pipeline并行数 。 pipeline并行数通常能整除层数，或者考虑embedding 层的时候能整出(层数+2)。</b></p><h3 id="h_670958880_15" data-into-catalog-status="">数据并行数</h3><p data-pid="Qc27DaUy">有更多机器，就数据并行；数据并行常用deepspeed zero数据并行，stage需要额外注意。</p><p data-pid="4-poJ1nw"><b>数据并行数 = 机器数 / tensor并行数 / pipeline并行数。 </b></p><p class="ztext-empty-paragraph"><br/></p><p data-pid="NP9ZL4R4">补充：文档中主要是推荐了一些取值范围，像是一个节点上有8个机器的时候，到底tensor并行数为2、4还是8，这个可能还是得看具体实验的结果；这个问题，目前我也没有理的很清楚，感觉还是得后面做一些具体实验，才能对这个问题有更深入、清晰的理解。</p><p class="ztext-empty-paragraph"><br/></p><h2 id="h_670958880_16" data-into-catalog-status=""> 4.架构分层</h2><p data-pid="qSj4imfN">从主流大模型对于并行策略的使用可以看出，基本都使用了两三种并行策略，为啥没人只用一种策略呢？</p><p data-pid="YUhMwBby">个人觉得这个跟GPU机器网络结构本来就是分层的有关。</p><p data-pid="12g-CBiD">基本都是多机N卡，这些模型训练用的卡数基本都是8。单机8卡之间的通信较快，而不同机器之间的通信速度较慢。</p><p data-pid="bTfMDWvh">如果采用一种并行训练策略，例如数据并行，那么一次梯度同步，需要所有卡进行通信，其中同一个机器上的通信已经完成，而不同机器上卡的通信还要一段时间，这浪费了机器内的带宽。</p><p data-pid="BZ1HjInC">因此对应于分层架构，主要是分层次的通信速度/带宽，需要采用分层的并行策略。最常见的就是机器内采用tensor 并行，机器外采用其他并行方案。</p><h2 id="h_670958880_17" data-into-catalog-status="">5.Megatron v2论文中和zero3的比较</h2><p data-pid="5J_ovfxY">论文名称： Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM </p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-2ee7f04bbe2f2e88cebc2302587099bc_b.jpg" data-caption="" data-size="normal" data-rawwidth="500" data-rawheight="239" class="origin_image zh-lightbox-thumb" width="500" data-original="https://pic1.zhimg.com/v2-2ee7f04bbe2f2e88cebc2302587099bc_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;239&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="500" data-rawheight="239" class="origin_image zh-lightbox-thumb lazy" width="500" data-original="https://pic1.zhimg.com/v2-2ee7f04bbe2f2e88cebc2302587099bc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-2ee7f04bbe2f2e88cebc2302587099bc_b.jpg" data-original-token="v2-4c5f5ba22910788438e0a48271a45c41"/></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-fbc4e242d8cee120ca382d259e1bc547_b.jpg" data-caption="" data-size="normal" data-rawwidth="1031" data-rawheight="408" class="origin_image zh-lightbox-thumb" width="1031" data-original="https://pic4.zhimg.com/v2-fbc4e242d8cee120ca382d259e1bc547_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1031&#39; height=&#39;408&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1031" data-rawheight="408" class="origin_image zh-lightbox-thumb lazy" width="1031" data-original="https://pic4.zhimg.com/v2-fbc4e242d8cee120ca382d259e1bc547_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-fbc4e242d8cee120ca382d259e1bc547_b.jpg" data-original-token="v2-cbb05a284495c49d0a5f516621d04861"/></figure><p data-pid="LN0Be-s-">PTD-P是pipeline、tensor、data parallelism三种方式的组合。</p><p data-pid="0LEvZDNN">从论文的比较来看，同样的模型、同样的机器资源下，PTD-P 可以获得比 只用zero3更好的训练效率，当2240卡时，能差出三倍多来。</p><blockquote data-pid="5_OAPwWa">For example, by doubling the number of GPUs (keep- ing the batch size the same), PTD-P outperforms ZeRO-3 by 70% for both models due to less cross-node communication </blockquote><p data-pid="-oCBsEQF">论文中觉得主要原因是zero3的跨节点通信更多，就是我们“架构分层“讨论的差不多。PTD在这里的优势就是tensor并行走的都是节点内的通信，数据并行、pipeline并行走节点间通信。而zero3每次都要节点间通信，自然就慢了。</p><p data-pid="kQduO_3o">当然这个是megatron的实验结果，也不能全信，换个人同样问题的实验就可能给出不一样的结论。例如一个问题，是他这里设置了固定的batch size，那多卡的实际操作的时候为了更好的结果，显存充足，利用率低完全可以增加micro batch size，那可能结论就不一样了。（= =！我也没有资源，我也只能保持怀疑态度，不能偏听偏信）</p><p class="ztext-empty-paragraph"><br/></p><blockquote data-pid="Jkl0kDqD">   we cannot use data parallelism in isolation for very large models with a limited training batch size because of a) insuffi- cient memory capacity, and b) scaling limitations of data parallelism (e.g., GPT-3 was trained to convergence with a batch size of 1536. Data parallelism thus supports parallelization to only 1536 GPUs; however, roughly 10, 000 GPUs were used to train this model in a reasonable amount of time). </blockquote><p data-pid="y2fWwxr7">v2这篇论文也提到了不能只用数据并行的两个原因：</p><p data-pid="Thn1_MgD">1.数据并行占用显存大。当然这个是说普通的数据并行，zero123显然降低了显存的使用</p><p data-pid="JcXa13oB">2.只数据并行时的 batch size  &gt;= 卡数，且是卡数的倍数。假设万卡，我就想batch size=100，只数据并行就不行了。</p></div></div></div></div><div role="button" tabindex="0" class="ContentItem-time">编辑于 2023-12-23 20:27<!-- -->・IP 属地北京</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><style data-emotion-css="ch8ocw">.css-ch8ocw{position:relative;display:inline-block;height:30px;padding:0 12px;font-size:14px;line-height:30px;color:#1772F6;vertical-align:top;border-radius:100px;background:rgba(23,114,246,0.1);}.css-ch8ocw:hover{background-color:rgba(23,114,246,0.15);}</style><div class="Tag Topic css-ch8ocw"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/26541450" target="_blank"><style data-emotion-css="1xlfegr">.css-1xlfegr{background:transparent;box-shadow:none;}</style><style data-emotion-css="1gomreu">.css-1gomreu{position:relative;display:inline-block;}</style><div class="css-1gomreu">模型并行</div></a></span></div><div class="Tag Topic css-ch8ocw"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/26797383" target="_blank"><div class="css-1gomreu">LLM（大型语言模型）</div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 528 " aria-live="polite" type="button" class="Button VoteButton VoteButton--up FEfUrdfMIKpQDJDqkjte"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor"><path fill-rule="evenodd" d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023Z" clip-rule="evenodd"></path></svg></span>赞同 528</button><button aria-label="反对" aria-live="polite" type="button" class="Button VoteButton VoteButton--down FEfUrdfMIKpQDJDqkjte"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleDown" fill="currentColor"><path fill-rule="evenodd" d="M13.792 20.319c-.781 1.406-2.803 1.406-3.584 0L2.418 6.296c-.76-1.367.228-3.046 1.791-3.046h15.582c1.563 0 2.55 1.68 1.791 3.046l-7.79 14.023Z" clip-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn FEfUrdfMIKpQDJDqkjte Button--plain Button--withIcon Button--withLabel fEPKGkUK5jyc4fUuT0QP B46v1Ak6Gj5sL2JTS4PY RuuQ6TOh2cRzJr6WlyQp"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Comment Button-zi t2ntD6J1DemdOdvh5FB4" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span>21 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false"><button type="button" class="Button FEfUrdfMIKpQDJDqkjte Button--plain Button--withIcon Button--withLabel fEPKGkUK5jyc4fUuT0QP B46v1Ak6Gj5sL2JTS4PY RuuQ6TOh2cRzJr6WlyQp"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Share Button-zi t2ntD6J1DemdOdvh5FB4" fill="currentColor"><path d="M19.47 1.914a.8.8 0 0 1 1.204.778l-1.872 16.386a.9.9 0 0 1-1.204.743l-4.615-1.692a.7.7 0 0 0-.831.28l-1.927 3.02c-.43.674-1.474.369-1.474-.43v-3.865a.8.8 0 0 1 .179-.504l5.808-7.148a.595.595 0 0 0-.897-.781l-5.93 6.354a1.1 1.1 0 0 1-1.258.252L2.57 13.46a.8.8 0 0 1-.08-1.415l16.98-10.13Z"></path></svg></span>分享</button></div></div><button aria-live="polite" type="button" class="Button ContentItem-action FEfUrdfMIKpQDJDqkjte Button--plain Button--withIcon Button--withLabel fEPKGkUK5jyc4fUuT0QP B46v1Ak6Gj5sL2JTS4PY RuuQ6TOh2cRzJr6WlyQp"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Heart Button-zi t2ntD6J1DemdOdvh5FB4" fill="currentColor"><path fill-rule="evenodd" d="M12.004 4.934c1.015-.944 2.484-1.618 3.98-1.618 3.48 0 6.53 3.265 6.15 7.614-.11 1.254-.686 2.55-1.458 3.753-.778 1.215-1.79 2.392-2.845 3.419-1.054 1.028-2.168 1.923-3.161 2.566a9.96 9.96 0 0 1-1.41.777c-.418.182-.862.32-1.268.32s-.848-.137-1.267-.317a9.918 9.918 0 0 1-1.407-.771c-.992-.64-2.103-1.53-3.156-2.555-1.052-1.024-2.062-2.2-2.84-3.417-.77-1.208-1.346-2.51-1.456-3.775-.38-4.349 2.67-7.614 6.15-7.614 1.484 0 2.983.673 3.988 1.618Z" clip-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button FEfUrdfMIKpQDJDqkjte Button--plain Button--withIcon Button--withLabel fEPKGkUK5jyc4fUuT0QP B46v1Ak6Gj5sL2JTS4PY RuuQ6TOh2cRzJr6WlyQp"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Star Button-zi t2ntD6J1DemdOdvh5FB4" fill="currentColor"><path d="M10.484 3.307c.673-1.168 2.358-1.168 3.032 0l2.377 4.122a.25.25 0 0 0 .165.12l4.655.987c1.319.28 1.84 1.882.937 2.884l-3.186 3.535a.25.25 0 0 0-.063.193l.5 4.733c.142 1.34-1.222 2.33-2.453 1.782l-4.346-1.938a.25.25 0 0 0-.204 0l-4.346 1.938c-1.231.549-2.595-.442-2.453-1.782l.5-4.733a.25.25 0 0 0-.064-.193L2.35 11.42c-.903-1.002-.382-2.604.937-2.884l4.655-.987a.25.25 0 0 0 .164-.12l2.378-4.122Z"></path></svg></span>收藏</button><button type="button" class="Button ContentItem-action FEfUrdfMIKpQDJDqkjte Button--plain Button--withIcon Button--withLabel fEPKGkUK5jyc4fUuT0QP B46v1Ak6Gj5sL2JTS4PY RuuQ6TOh2cRzJr6WlyQp"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Deliver Button-zi t2ntD6J1DemdOdvh5FB4" fill="currentColor"><g fill-rule="evenodd" clip-rule="evenodd"><path d="M7.821 12a.75.75 0 0 1 .75-.75h6.857a.75.75 0 0 1 0 1.5H8.571a.75.75 0 0 1-.75-.75ZM8.965 8a.75.75 0 0 1 .75-.75h4.571a.75.75 0 0 1 0 1.5H9.715a.75.75 0 0 1-.75-.75Z"></path><path d="M7.527 3.15a2.35 2.35 0 0 0-2.309 1.91L3.165 15.84a.85.85 0 0 0-.015.16v2.5a2.35 2.35 0 0 0 2.35 2.35h13a2.35 2.35 0 0 0 2.35-2.35V16a.848.848 0 0 0-.015-.16L18.78 5.06a2.35 2.35 0 0 0-2.308-1.91H7.527Zm0 1.7a.65.65 0 0 0-.639.528l-1.88 9.872h13.984l-1.88-9.872a.65.65 0 0 0-.64-.528H7.528Z"></path></g></svg></span>申请转载</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false"><button type="button" class="Button FEfUrdfMIKpQDJDqkjte Button--plain Button--withIcon Button--iconOnly fEPKGkUK5jyc4fUuT0QP B46v1Ak6Gj5sL2JTS4PY hIwDV_tcL6XN1HprrnAq"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Dots Button-zi t2ntD6J1DemdOdvh5FB4" fill="currentColor"><path d="M6 10.5a1.5 1.5 0 1 0 0 3 1.5 1.5 0 0 0 0-3ZM10.5 12a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0ZM16.5 12a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Z"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="//www.zhihu.com/column/c_1363448145687584768"><div class="css-1gomreu"><style data-emotion-css="1u7r5c9">.css-1u7r5c9{box-sizing:border-box;margin:0;min-width:0;max-width:100%;height:auto;background-color:#ffffff;width:40px;height:40px;border-radius:50%;}</style><img class="Avatar css-1u7r5c9" src="https://picx.zhimg.com/4b70deef7_l.jpg?source=172ae18b" srcSet="https://picx.zhimg.com/4b70deef7_l.jpg?source=172ae18b 2x" alt="关于算法工作的一些记录"/></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span><a class="ColumnLink ColumnItem-Title" href="//www.zhihu.com/column/c_1363448145687584768"><div class="css-1gomreu">关于算法工作的一些记录</div></a></span></h2><div class="ContentItem-meta">笔记，整理，复盘</div></div></div></div><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="//www.zhihu.com/column/c_1695749314725486593"><div class="css-1gomreu"><img class="Avatar css-1u7r5c9" src="https://picx.zhimg.com/4b70deef7_l.jpg?source=172ae18b" srcSet="https://picx.zhimg.com/4b70deef7_l.jpg?source=172ae18b 2x" alt="计算机&amp;通信技术"/></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span><a class="ColumnLink ColumnItem-Title" href="//www.zhihu.com/column/c_1695749314725486593"><div class="css-1gomreu">计算机&amp;通信技术</div></a></span></h2><div class="ContentItem-meta">关于技术的学习与总结。</div></div></div></div></ul></div></div></div></main></div></div><script id="js-clientConfig" type="text/json">{"fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","lens":"https:\u002F\u002Flens.zhihu.com","zhida":"https:\u002F\u002Fzhida.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fapi\u002F","walletpay":"https:\u002F\u002Fwalletpay.zhihu.com","captcha":"https:\u002F\u002Fcaptcha.zhihu.com","vzuu":"https:\u002F\u002Fv.vzuu.com","openapi":"https:\u002F\u002Fopenapi.zhihu.com","svip":"https:\u002F\u002Fsvip.zhihu.com"},"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","videoHost":"video.zhihu.com","zhuanlanHost":"zhuanlan.zhihu.com","allowSignUp":true,"refreshValidityPeriod":"30","release":"1469-87f58f34","currentEntry":"column","isMobileEntry":false,"apollo":{"env":"prod","globalSilence":"","ncgModeSign":"3f8e56febda4fb3bbea72e379d76de1e","topstory_rec_adp":"1","topstory_hot_adp":"1","editor_adapt_native":"0","editor_auto_rotate":"0","enable_request_filter":"1","content_publish_pin":"0","content_publish_answer":"1","content_publish_question":"1","content_publish_article":"1","content_publish_zvideo":"1","balanceModalSign":"ChYHAcB5ihJECkAFnhDAYmdhsTWVJoNc","reportBackendPublishError":"1","dynamic_font_schema":"1","enable_vzuu_login":"on","test_canary":"member|0-100,1-0","use_new_player":"member|0-100,1-0","player_vendor":"member|0-100,1-0,2-0","use_hevc":"member|0-0,1-100","upload_use_signature":"member|0-0,1-100","use_backdrop_blur":"member|0-0,1-100","article_title_imagex":"member|0-0,1-100","play_station":"member|0-0,1-100","use_cached_supported_countries":"device|1-100,0-0","contentItem_cover_imagex":"member|0-0,1-100","use_qrcode_login_v2":"device|1-100,0-0"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{},"cities":{"cityData":[]}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false,"article\u002FloadPostSearchEntity\u002F":false}},"entities":{"users":{"a70b9eb6781d764f023eb2a26684f261":{"uid":43709722787840,"userType":"people","id":"a70b9eb6781d764f023eb2a26684f261"},"lu-kai-14-46":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5.jpg?source=172ae18b","uid":"45037148700672","userType":"people","isFollowing":false,"urlToken":"lu-kai-14-46","id":"ba21f2a3b0e2f3b7fd2244cf6352cf2d","description":"","name":"流逝","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002Fba21f2a3b0e2f3b7fd2244cf6352cf2d","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"972477022068568064","medalName":"备受瞩目","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-7565d834d652a9960da0cedd8d7952ee_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7565d834d652a9960da0cedd8d7952ee_l.png?source=172ae18b","description":"被 100 个人关注","medalAvatarFrame":""}}},"questions":{},"answers":{},"articles":{"670958880":{"entityWords":[],"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fcontent_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=BiBUKF0xBSkqGGZXB2F-AVu1iGunkm-QLQ==&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__&zid=__ZONEID__"],"id":670958880,"title":"模型并行训练：为什么要用Megatron，DeepSpeed不够用吗？","type":"article","articleType":"normal","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F670958880","imageUrl":"","titleImage":"","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-546d0b6cf13ebb000f6c23d7a8ae0e4b_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"878\" data-rawheight=\"447\" data-watermark=\"watermark\" data-original-src=\"v2-546d0b6cf13ebb000f6c23d7a8ae0e4b\" data-watermark-src=\"v2-3f70e4435d0a7e2d92ea8eca29d82b82\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-546d0b6cf13ebb000f6c23d7a8ae0e4b_r.png\"\u002F\u003E背景最近工作要解答的问题：为什么要用Megatron，DeepSpeed不够用吗？ 回答：因为领导要用（划去，bushi）。 领导：回去好好调研一下，下周给大领导汇报 1.Megatron相比于DeepSpeed的特性我们看一下BLOOM中对megatron+deepspeed的使用。 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fhuggingface\u002Fblog\u002Fblob\u002Fmain\u002Fbloom-megatron-deepspeed.md\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EThe Technology Beh…\u003C\u002Fa\u003E","created":1701942483,"updated":1703334446,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5.jpg?source=172ae18b","uid":"45037148700672","userType":"people","isFollowing":false,"urlToken":"lu-kai-14-46","id":"ba21f2a3b0e2f3b7fd2244cf6352cf2d","description":"","name":"流逝","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002Fba21f2a3b0e2f3b7fd2244cf6352cf2d","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"972477022068568064","medalName":"备受瞩目","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-7565d834d652a9960da0cedd8d7952ee_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-7565d834d652a9960da0cedd8d7952ee_l.png?source=172ae18b","description":"被 100 个人关注","medalAvatarFrame":""}},"commentPermission":"all","copyrightPermission":"need_review","state":"published","ipInfo":"IP 属地北京","imageWidth":0,"imageHeight":0,"content":"\u003Ch2\u003E背景\u003C\u002Fh2\u003E\u003Cp data-pid=\"g9viJcYw\"\u003E最近工作要解答的问题：为什么要用Megatron，DeepSpeed不够用吗？\u003C\u002Fp\u003E\u003Cp data-pid=\"HjnsNzAm\"\u003E回答：因为领导要用（划去，bushi）。\u003C\u002Fp\u003E\u003Cp data-pid=\"fLv3dHgo\"\u003E领导：回去好好调研一下，下周给大领导汇报\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003E1.Megatron相比于DeepSpeed的特性\u003C\u002Fh2\u003E\u003Cp data-pid=\"DULPX-K7\"\u003E我们看一下BLOOM中对megatron+deepspeed的使用。\u003C\u002Fp\u003E\u003Cp data-pid=\"MDOUfcoC\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fhuggingface\u002Fblog\u002Fblob\u002Fmain\u002Fbloom-megatron-deepspeed.md\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EThe Technology Behind BLOOM Training\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"PGTesN5S\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fhuggingface.co\u002Fblog\u002Fzh\u002Fbloom-megatron-deepspeed%23datasets\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E千亿参数开源大模型 BLOOM 背后的技术\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"lnlf2til\"\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fhuggingface.co\u002Fblog\u002Fzh\u002Fmegatron-training\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E如何使用 Megatron-LM 训练语言模型\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3f70e4435d0a7e2d92ea8eca29d82b82_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"878\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"878\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3f70e4435d0a7e2d92ea8eca29d82b82_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;878&#39; height=&#39;447&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"878\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"878\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3f70e4435d0a7e2d92ea8eca29d82b82_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3f70e4435d0a7e2d92ea8eca29d82b82_b.jpg\" data-original-token=\"v2-546d0b6cf13ebb000f6c23d7a8ae0e4b\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"xiojnsYy\"\u003E容易得出，在BLOOM看来，tensor并行、Fused CUDA Kernels 和 DataLoader 是Megatron相对于 DeepSpeed 的三大特点。\u003C\u002Fp\u003E\u003Ch3\u003ETensor并行\u003C\u002Fh3\u003E\u003Cp data-pid=\"Jlr3_heX\"\u003E比较好理解，具体看Megatron论文，就是把一个神经网络层Tensor切成了多个小的Tensor，每个tensor放在不同的gpu。主要就是列并行、行并行。在transformer里的应用具体体现在MLP、Attention层里。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6ea73fd9877c26c2e37a0d08fdbf0854_b.jpg\" data-size=\"normal\" data-rawwidth=\"1624\" data-rawheight=\"1320\" class=\"origin_image zh-lightbox-thumb\" width=\"1624\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6ea73fd9877c26c2e37a0d08fdbf0854_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1624&#39; height=&#39;1320&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1624\" data-rawheight=\"1320\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1624\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6ea73fd9877c26c2e37a0d08fdbf0854_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6ea73fd9877c26c2e37a0d08fdbf0854_b.jpg\" data-original-token=\"v2-559b93c1ffaae85d69bd53b0fadf75db\"\u002F\u003E\u003Cfigcaption\u003ETensor并行：列并行、行并行\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EFused CUDA Kernels\u003C\u002Fh3\u003E\u003Cp data-pid=\"r5XVaCsf\"\u003E简单来说，就是nvidia对cuda运算的优化，这部分代码在Megatron代码里都是c\u002Fc++。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-be77c1446ba060be9e010bd3fd9b99d4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1334\" data-rawheight=\"564\" class=\"origin_image zh-lightbox-thumb\" width=\"1334\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-be77c1446ba060be9e010bd3fd9b99d4_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1334&#39; height=&#39;564&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1334\" data-rawheight=\"564\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1334\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-be77c1446ba060be9e010bd3fd9b99d4_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-be77c1446ba060be9e010bd3fd9b99d4_b.jpg\" data-original-token=\"v2-5739a9eb93f7460352ca020b4a52d3c2\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"Yg-UDfKE\"\u003E如图的例子，本来这个计算涉及到三个函数，需要换进换出显存三次。融合后，只需要一次换进换出了。加快了计算速度。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch3\u003EDataLoader\u003C\u002Fh3\u003E\u003Cp data-pid=\"-sM-kwvB\"\u003E通过提前做tokenize、shuffle做成文件，训练时每个epoch根据索引来获取数据。\u003C\u002Fp\u003E\u003Cp data-pid=\"yfmMXhRk\"\u003E我其实个人觉得这玩意没啥，在之前微调7b模型的时候，数据处理的耗时跟模型训练的耗时跟本没法比。当然有的人觉得能快一点是一点。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003E2.主流大模型中对Megatron的使用\u003C\u002Fh2\u003E\u003Cp data-pid=\"mlxdhr2L\"\u003E领导，你看人家都用这玩意，咱是不是也得用一下？\u003C\u002Fp\u003E\u003Ctable data-draft-node=\"block\" data-draft-type=\"table\" data-size=\"normal\" data-row-style=\"normal\"\u003E\u003Ctbody\u003E\u003Ctr\u003E\u003Cth\u003E模型\u003C\u002Fth\u003E\u003Cth\u003E机器\u002F显卡\u003C\u002Fth\u003E\u003Cth\u003Etensor并行\u003C\u002Fth\u003E\u003Cth\u003Epipeline并行\u003C\u002Fth\u003E\u003Cth\u003E数据并行\u003C\u002Fth\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003EGLM130B\u003C\u002Ftd\u003E\u003Ctd\u003E96机 8卡 40G A100\u003C\u002Ftd\u003E\u003Ctd\u003Etp=4\u003C\u002Ftd\u003E\u003Ctd\u003Epp=8\u003C\u002Ftd\u003E\u003Ctd\u003Edp=24, zero stage1\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003EBLOOM\u003C\u002Ftd\u003E\u003Ctd\u003E48机 8卡 80G A100\u003C\u002Ftd\u003E\u003Ctd\u003Etp=4\u003C\u002Ftd\u003E\u003Ctd\u003Epp=12\u003C\u002Ftd\u003E\u003Ctd\u003Edp=8, zero stage1\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003EOPT\u003C\u002Ftd\u003E\u003Ctd\u003E124机8卡80G A100\u003C\u002Ftd\u003E\u003Ctd\u003Etp=8\u003C\u002Ftd\u003E\u003Ctd\u003E没提\u003C\u002Ftd\u003E\u003Ctd\u003EFully Sharded Data Parallel，类似于zero stage3\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003EBaichuan-2\u003C\u002Ftd\u003E\u003Ctd\u003E128机8卡80GA800\u003C\u002Ftd\u003E\u003Ctd\u003E用了，没具体讲\u003C\u002Ftd\u003E\u003Ctd\u003E没提\u003C\u002Ftd\u003E\u003Ctd\u003Ezero stage3数据并行\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003ELLaMA1-65B\u003C\u002Ftd\u003E\u003Ctd\u003E256机8卡 80G\u003C\u002Ftd\u003E\u003Ctd\u003E用了，没具体讲\u003C\u002Ftd\u003E\u003Ctd\u003E用了，没具体讲\u003C\u002Ftd\u003E\u003Ctd\u003E没提到，疑似用了\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003C\u002Ftbody\u003E\u003C\u002Ftable\u003E\u003Ch3\u003EGLM-130B\u003C\u002Fh3\u003E\u003Cp data-pid=\"faTu0Zsr\"\u003E从论文附录看，GLM-130B尝试过使用DeepSpeed和Megatron，虽然最后的论文正文没提megatron。\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"8IiR5CEk\"\u003EMajor Issues Encountered for Training GLM-130B\u003Cbr\u002F\u003E2022.2  Debug the 3D pipeline parallel in the newly-released Megatron and DeepSpeed \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"-RrpIE3M\"\u003EGithub issue：\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"8GlNpq0s\"\u003EUnlike OPT-175B and BLOOM-176B, we use 40G A100 instead of its 80G version, so the GPU memory could be very tight for training. We have tried numerous combinations of parallelism \u002F hidden size \u002F layers and ended up using 4-way tensor and 8-way pipeline parallelism for the best training throughput, approximately 135 TFLOPS \u002F GPU. Adam optimizer with ZeRO stage 1 is used in actual training. At least 40 nodes are required to start training. Using optimizers like Adafactor or 8-bit Adam could further reduce the minimum requirement to 24 nodes, however, we did not use them for best convergence.\u003C\u002Fblockquote\u003E\u003Cp data-pid=\"FIxfHl3E\"\u003E很有意思的一点是，issue中提到了Adam二阶动量用的显存比较多，只用一阶动量的Adafactor可以明显减少显存使用，但是同样设置下Adam收敛得更好。\u003C\u002Fp\u003E\u003Cp data-pid=\"zrZ9RAOa\"\u003E很好奇，同样计算量、资源下，Adam换成其他优化器，减少显存，增加训练数据、训练时间，是不是效果会更好一些。毕竟Adam是2014年的产物了，当时不像现在，显存成为了很多人训练大模型的瓶颈。\u003C\u002Fp\u003E\u003Cp data-pid=\"U6sbQi6t\"\u003E96*8张卡，train了2个月。\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"ck9IW_eE\"\u003E   pre-trained over 400 billion tokens on a cluster of 96 NVIDIA DGX-A100 (8×40G) GPU nodes between May 6 and July 3, 2022 \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"ftiD3w0N\"\u003Etp=4，pp=8, dp=24, 数据并行采用zero stage1\u003C\u002Fp\u003E\u003Ch3\u003EBLOOM\u003C\u002Fh3\u003E\u003Cp data-pid=\"VxlafGGy\"\u003E论文原文：\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"F6WNVqf2\"\u003E 3.4.2 Framework \u003Cbr\u002F\u003E BLOOM was trained using Megatron-DeepSpeed20 (Smith et al., 2022), a framework for large-scale distributed training. It consists of two parts: Megatron-LM21 (Shoeybi et al., 2019) provides the Transformer implementation, tensor parallelism, and data loading prim- itives, whereas DeepSpeed22 (Rasley et al., 2020) provides the ZeRO optimizer, model pipelining, and general distributed training components. This framework allows us to train efficiently with 3D parallelism (Narayanan et al., 2021, shown in Figure 6), a fusion of three complementary approaches to distributed training. \u003C\u002Fblockquote\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d1d1bd26589af3b7edfaadc8884aa79b_b.jpg\" data-size=\"normal\" data-rawwidth=\"1732\" data-rawheight=\"954\" class=\"origin_image zh-lightbox-thumb\" width=\"1732\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d1d1bd26589af3b7edfaadc8884aa79b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1732&#39; height=&#39;954&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1732\" data-rawheight=\"954\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1732\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d1d1bd26589af3b7edfaadc8884aa79b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d1d1bd26589af3b7edfaadc8884aa79b_b.jpg\" data-original-token=\"v2-67bd5a416910a98b278e90252dcfa426\"\u002F\u003E\u003Cfigcaption\u003EBLOOM论文中的3D并行\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cblockquote data-pid=\"EfNyVhjy\"\u003E We used ZeRO stage 1, meaning that only the optimizer states are sharded in this manner. \u003Cbr\u002F\u003E The four components described above are combined together to allow scaling to hundreds of GPUs with extremely high GPU utilization. We were able to achieve 156 TFLOPs in our fastest configuration with A100 GPUs, attaining our objective of half of the theoretical peak performance of 312 TFLOPs (in float32 or bfloat16). \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"raH224Sy\"\u003E硬件：\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"f5r4DiUB\"\u003ETraining was conducted on 48 nodes, each having 8 NVIDIA A100 80GB GPUs (a total of 384 GPUs); due to possible hardware failures during training, we also maintained a reserve of 4 spare nodes. The nodes were equipped with 2x AMD EPYC 7543 32-Core CPUs and 512 GB of RAM, while the storage was handled by mix of full flash and hard disk drives using a SpectrumScale (GPFS) parallel file system shared between all nodes and users of the supercomputer. 4 NVLink GPU-to- GPU interconnects per node enabled intra-node communications while 4 Omni-Path 100 Gbps links per node, arranged in an enhanced hypercube 8D global topology, were used for inter-node communications. \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"TGIhVFsX\"\u003E48*8 个80G A100\u003C\u002Fp\u003E\u003Cp data-pid=\"NM8t0Xes\"\u003Etensor并行数=4，pipeline并行数=12，数据并行数=8，数据并行采用zero stage1。\u003C\u002Fp\u003E\u003Ch3\u003EOPT\u003C\u002Fh3\u003E\u003Cblockquote data-pid=\"uAu8pIM-\"\u003Eenabled training OPT-175B on 992 80GB A100 GPUs, reaching 147 TFLOP\u002Fs utilization per GPU. \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"j9xg1sFO\"\u003E应该是992=124*8个 80G A100\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"zYcrvYVj\"\u003E2.4 Training Efficiency \u003Cbr\u002F\u003E We trained OPT-175B on 992 80GB A100 GPUs, by utilizing Fully Sharded Data Parallel (Artetxe et al., 2021) with Megatron-LM Tensor Parallelism (Shoeybi et al., 2019). We achieve utilization of up to 147 TFLOP\u002Fs per GPU. We keep Adam state in FP32, since we shard it across all hosts, while the model weights remained in FP16. To avoid under- flows, we used dynamic loss scaling, as described in Micikevicius et al. (2017). \u003C\u002Fblockquote\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"8B2nKN9s\"\u003E[2021-11-05] Run 11.0: LETS GO\u003Cbr\u002F\u003E● Tensor parallel (8x MP)\u003C\u002Fblockquote\u003E\u003Cp data-pid=\"ANUdLgPW\"\u003Etensor并行数=8。数据并行采用Fully Sharded Data Parallel，这个具体不太懂。8*80G明显放不下175B的模型训练，估计Fully Sharded Data Parallel类似于zero做了模型上的切分。\u003C\u002Fp\u003E\u003Ch3\u003EBaichuan-2\u003C\u002Fh3\u003E\u003Cblockquote data-pid=\"wavRIVcW\"\u003E efficiently on 1,024 NVIDIA A800 GPUs, achieving a computational efficiency that exceeds 180 TFLOPS.\u003C\u002Fblockquote\u003E\u003Cp data-pid=\"XZ3oN-3J\"\u003E128*8个\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"PX2MkJWJ\"\u003Eour training framework integrates tensor parallelism (Narayanan et al., 2021) and ZeRO- powered data parallelism (Rajbhandari et al., 2020), where we set tensor parallelism inside each machine and employ ZeRO shared data parallelism for elastic scaling across machines. \u003Cbr\u002F\u003E \u003Ci\u003EHybrid and hierarchical partition for ZeRO\u003C\u002Fi\u003E. By partitioning parameters across GPUs, ZeRO3 reduces memory consumption at the expense of additional all-gather communications.  \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"tMynef-7\"\u003E主要使用了tensor并行 和 zero3数据并行，另外加了一些其他自己搞的方法。\u003C\u002Fp\u003E\u003Ch3\u003EGPT3\u003C\u002Fh3\u003E\u003Cblockquote data-pid=\"LnAHKuCr\"\u003ETo train the larger models without running out of memory, we use a mixture of model parallelism within each matrix multiply and model parallelism across the layers of the network. All models were trained on V100 GPU’s on part of a high-bandwidth cluster provided by Microsoft.  \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"6crJd_sp\"\u003E具体没写啥。\u003C\u002Fp\u003E\u003Ch3\u003ELLaMA1-65B\u003C\u002Fh3\u003E\u003Cblockquote data-pid=\"2K8EHVEU\"\u003E   reduce the memory usage of the model by using model and sequence parallelism, as described by Korthikanti et al. (2022). Moreover, we also over- lap the computation of activations and the commu- nication between GPUs over the network (due to all_reduce operations) as much as possible. \u003Cbr\u002F\u003E When training a 65B-parameter model, our code processes around 380 tokens\u002Fsec\u002FGPU on 2048 A100 GPU with 80GB of RAM.  \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"D3lE-6xQ\"\u003E256机8卡 80G A100\u003C\u002Fp\u003E\u003Cp data-pid=\"seYyERoC\"\u003Etensor并行，pipeline并行\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003E3.Megatron中tensor并行数、pipeline并行数、数据并行数等各并行参数如何确定取值范围？\u003C\u002Fh2\u003E\u003Cp data-pid=\"mKzBCs-Y\"\u003E主要参考：\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fhuggingface.co\u002Fdocs\u002Ftransformers\u002Fmain\u002Fen\u002Fperf_train_gpu_many\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003EEfficient Training on Multiple GPUs\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"d_sDrPxB\"\u003E这里面讨论的情况比较复杂，我的个人理解和总结如下：\u003C\u002Fp\u003E\u003Cp data-pid=\"_-GJTXa5\"\u003E基于给定模型、给定输入长度、给定机器的情况下。\u003C\u002Fp\u003E\u003Ch3\u003ETensor并行数\u003C\u002Fh3\u003E\u003Cp data-pid=\"izuhV5VQ\"\u003Etensor并行无气泡等额外计算；但是同步的数据量大，需要快的网络，因此都是在单个机器上；模型太大，单个层在gpu放不下，也得tensor并行。\u003C\u002Fp\u003E\u003Cp data-pid=\"QoRQtXJu\"\u003E\u003Cb\u003E放得下单层 &lt;= tensor并行数 &lt;= 单机卡数 \u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Ch3\u003EPipeline并行数\u003C\u002Fh3\u003E\u003Cp data-pid=\"q27LKUFe\"\u003Epp通信快，适合通信慢模型大到单卡\u002F单机放不下的场景；存在气泡；tensor并行放不下，再用pipeline并行。\u003C\u002Fp\u003E\u003Cp data-pid=\"c-QcdQ44\"\u003E多大机器能放的下模型参数，这个得具体算一下，计算方法可参考：\u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F624740065\" class=\"internal\"\u003E回旋托马斯x：分析transformer模型的参数量、计算量、中间激活、KV cache\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"UXomjv7s\"\u003E通过micro batch来减少pipeline并行的气泡，提高训练效率。\u003C\u002Fp\u003E\u003Cp data-pid=\"YSGX0ZNH\"\u003E\u003Cb\u003E放得下模型参数 &lt;= tensor并行数 * pipeline并行数 。 pipeline并行数通常能整除层数，或者考虑embedding 层的时候能整出(层数+2)。\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Ch3\u003E数据并行数\u003C\u002Fh3\u003E\u003Cp data-pid=\"Qc27DaUy\"\u003E有更多机器，就数据并行；数据并行常用deepspeed zero数据并行，stage需要额外注意。\u003C\u002Fp\u003E\u003Cp data-pid=\"4-poJ1nw\"\u003E\u003Cb\u003E数据并行数 = 机器数 \u002F tensor并行数 \u002F pipeline并行数。 \u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"NP9ZL4R4\"\u003E补充：文档中主要是推荐了一些取值范围，像是一个节点上有8个机器的时候，到底tensor并行数为2、4还是8，这个可能还是得看具体实验的结果；这个问题，目前我也没有理的很清楚，感觉还是得后面做一些具体实验，才能对这个问题有更深入、清晰的理解。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003E 4.架构分层\u003C\u002Fh2\u003E\u003Cp data-pid=\"qSj4imfN\"\u003E从主流大模型对于并行策略的使用可以看出，基本都使用了两三种并行策略，为啥没人只用一种策略呢？\u003C\u002Fp\u003E\u003Cp data-pid=\"YUhMwBby\"\u003E个人觉得这个跟GPU机器网络结构本来就是分层的有关。\u003C\u002Fp\u003E\u003Cp data-pid=\"12g-CBiD\"\u003E基本都是多机N卡，这些模型训练用的卡数基本都是8。单机8卡之间的通信较快，而不同机器之间的通信速度较慢。\u003C\u002Fp\u003E\u003Cp data-pid=\"bTfMDWvh\"\u003E如果采用一种并行训练策略，例如数据并行，那么一次梯度同步，需要所有卡进行通信，其中同一个机器上的通信已经完成，而不同机器上卡的通信还要一段时间，这浪费了机器内的带宽。\u003C\u002Fp\u003E\u003Cp data-pid=\"BZ1HjInC\"\u003E因此对应于分层架构，主要是分层次的通信速度\u002F带宽，需要采用分层的并行策略。最常见的就是机器内采用tensor 并行，机器外采用其他并行方案。\u003C\u002Fp\u003E\u003Ch2\u003E5.Megatron v2论文中和zero3的比较\u003C\u002Fh2\u003E\u003Cp data-pid=\"5J_ovfxY\"\u003E论文名称： Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM \u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2ee7f04bbe2f2e88cebc2302587099bc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"239\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2ee7f04bbe2f2e88cebc2302587099bc_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;500&#39; height=&#39;239&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"239\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2ee7f04bbe2f2e88cebc2302587099bc_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2ee7f04bbe2f2e88cebc2302587099bc_b.jpg\" data-original-token=\"v2-4c5f5ba22910788438e0a48271a45c41\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-fbc4e242d8cee120ca382d259e1bc547_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1031\" data-rawheight=\"408\" class=\"origin_image zh-lightbox-thumb\" width=\"1031\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-fbc4e242d8cee120ca382d259e1bc547_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1031&#39; height=&#39;408&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1031\" data-rawheight=\"408\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1031\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-fbc4e242d8cee120ca382d259e1bc547_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-fbc4e242d8cee120ca382d259e1bc547_b.jpg\" data-original-token=\"v2-cbb05a284495c49d0a5f516621d04861\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"LN0Be-s-\"\u003EPTD-P是pipeline、tensor、data parallelism三种方式的组合。\u003C\u002Fp\u003E\u003Cp data-pid=\"0LEvZDNN\"\u003E从论文的比较来看，同样的模型、同样的机器资源下，PTD-P 可以获得比 只用zero3更好的训练效率，当2240卡时，能差出三倍多来。\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"5_OAPwWa\"\u003EFor example, by doubling the number of GPUs (keep- ing the batch size the same), PTD-P outperforms ZeRO-3 by 70% for both models due to less cross-node communication \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"-oCBsEQF\"\u003E论文中觉得主要原因是zero3的跨节点通信更多，就是我们“架构分层“讨论的差不多。PTD在这里的优势就是tensor并行走的都是节点内的通信，数据并行、pipeline并行走节点间通信。而zero3每次都要节点间通信，自然就慢了。\u003C\u002Fp\u003E\u003Cp data-pid=\"kQduO_3o\"\u003E当然这个是megatron的实验结果，也不能全信，换个人同样问题的实验就可能给出不一样的结论。例如一个问题，是他这里设置了固定的batch size，那多卡的实际操作的时候为了更好的结果，显存充足，利用率低完全可以增加micro batch size，那可能结论就不一样了。（= =！我也没有资源，我也只能保持怀疑态度，不能偏听偏信）\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cblockquote data-pid=\"Jkl0kDqD\"\u003E   we cannot use data parallelism in isolation for very large models with a limited training batch size because of a) insuffi- cient memory capacity, and b) scaling limitations of data parallelism (e.g., GPT-3 was trained to convergence with a batch size of 1536. Data parallelism thus supports parallelization to only 1536 GPUs; however, roughly 10, 000 GPUs were used to train this model in a reasonable amount of time). \u003C\u002Fblockquote\u003E\u003Cp data-pid=\"y2fWwxr7\"\u003Ev2这篇论文也提到了不能只用数据并行的两个原因：\u003C\u002Fp\u003E\u003Cp data-pid=\"Thn1_MgD\"\u003E1.数据并行占用显存大。当然这个是说普通的数据并行，zero123显然降低了显存的使用\u003C\u002Fp\u003E\u003Cp data-pid=\"JcXa13oB\"\u003E2.只数据并行时的 batch size  &gt;= 卡数，且是卡数的倍数。假设万卡，我就想batch size=100，只数据并行就不行了。\u003C\u002Fp\u003E","contentNeedTruncated":false,"adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F26541450","type":"topic","id":"26541450","name":"模型并行"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F26797383","type":"topic","id":"26797383","name":"LLM（大型语言模型）"}],"voteupCount":528,"voting":0,"heavyUpStatus":"allow_heavy_up","column":{"description":"","canManage":false,"intro":"笔记，整理，复盘","isFollowing":false,"urlToken":"c_1363448145687584768","id":"c_1363448145687584768","articlesCount":31,"acceptSubmission":false,"title":"关于算法工作的一些记录","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1363448145687584768","commentPermission":"all","created":1617851369,"updated":1704718581,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5.jpg?source=172ae18b","uid":"45037148700672","userType":"people","isFollowing":false,"urlToken":"lu-kai-14-46","id":"ba21f2a3b0e2f3b7fd2244cf6352cf2d","description":"","name":"流逝","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002Fba21f2a3b0e2f3b7fd2244cf6352cf2d","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":0,"type":"column"},"commentCount":21,"contributions":[{"id":47293884,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"笔记，整理，复盘","isFollowing":false,"urlToken":"c_1363448145687584768","id":"c_1363448145687584768","articlesCount":31,"acceptSubmission":false,"title":"关于算法工作的一些记录","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1363448145687584768","commentPermission":"all","created":1617851369,"updated":1704718581,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5.jpg?source=172ae18b","uid":"45037148700672","userType":"people","isFollowing":false,"urlToken":"lu-kai-14-46","id":"ba21f2a3b0e2f3b7fd2244cf6352cf2d","description":"","name":"流逝","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002Fba21f2a3b0e2f3b7fd2244cf6352cf2d","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":0,"type":"column"}},{"id":48753115,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"关于技术的学习与总结。","isFollowing":false,"urlToken":"c_1695749314725486593","id":"c_1695749314725486593","articlesCount":32,"acceptSubmission":false,"title":"计算机&通信技术","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1695749314725486593","commentPermission":"all","created":1697078142,"updated":1697078142,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-c86f0bffbbb4b0e0814bf0f2504689ac.jpg?source=172ae18b","uid":"918954495759773696","userType":"people","isFollowing":false,"urlToken":"zhy-72-18","id":"192c974c8b6ce0e0e358adf6e92a737b","description":"","name":"楚江南","isAdvertiser":false,"headline":"","gender":-1,"url":"\u002Fpeople\u002F192c974c8b6ce0e0e358adf6e92a737b","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-c86f0bffbbb4b0e0814bf0f2504689ac_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":0,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"favlistsCount":1039,"isNormal":true,"status":0,"activityToppingInfo":{"state":"untopped"},"shareText":"模型并行训练：为什么要用Megatron，DeepSpeed不够用吗？ - 来自知乎专栏「关于算法工作的一些记录」，作者: 流逝 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F670958880 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":63,"hasColumn":true,"republishers":[{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-c86f0bffbbb4b0e0814bf0f2504689ac.jpg?source=172ae18b","uid":"918954495759773696","userType":"people","isFollowing":false,"urlToken":"zhy-72-18","id":"192c974c8b6ce0e0e358adf6e92a737b","description":"","name":"楚江南","isAdvertiser":false,"headline":"","gender":-1,"url":"\u002Fpeople\u002F192c974c8b6ce0e0e358adf6e92a737b","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-c86f0bffbbb4b0e0814bf0f2504689ac_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}}],"isNewLinkCard":true,"emojiReaction":{"likeCount":63,"likeHasSet":false},"abParam":{"pnNbtoolbar":"0","qaFotoolbar":"1","qaHiddenVoteup":"1","qaNewdownvote":"1","rsInterest1":"","zpZhiStyle":""},"attachedInfo":"kgIkCgkyMzcyMzIxMDcSCTY3MDk1ODg4MBgHIgpJTUFHRV9URVhU","shareGuide":{"hasPositiveBubble":false,"hasTimeBubble":false,"hitShareGuideCluster":false},"settings":{"tableOfContents":{"enabled":true}},"canReference":false,"reactionInstruction":{},"reaction":{"statistics":{"upVoteCount":528,"downVoteCount":0,"likeCount":63,"commentCount":21,"shareCount":0,"playCount":0,"interestPlayCount":0,"favorites":1039,"pvCount":0,"bulletCount":0,"applaudCount":0,"questionFollowerCount":0,"questionAnswerCount":0,"plaincontentVoteUpCount":0,"plaincontentLikeCount":0,"imgLikeCount":{"v24c5f5ba22910788438e0a48271a45c41":0,"v2546d0b6cf13ebb000f6c23d7a8ae0e4b":0,"v2559b93c1ffaae85d69bd53b0fadf75db":4,"v25739a9eb93f7460352ca020b4a52d3c2":1,"v267bd5a416910a98b278e90252dcfa426":2,"v2Cbb05a284495c49d0a5f516621d04861":0}},"relation":{"isAuthor":false,"vote":"Neutral","liked":false,"imgLiked":{"v24c5f5ba22910788438e0a48271a45c41":false,"v2546d0b6cf13ebb000f6c23d7a8ae0e4b":false,"v2559b93c1ffaae85d69bd53b0fadf75db":false,"v25739a9eb93f7460352ca020b4a52d3c2":false,"v267bd5a416910a98b278e90252dcfa426":false,"v2Cbb05a284495c49d0a5f516621d04861":false},"faved":false},"imageReactions":{"v24c5f5ba22910788438e0a48271a45c41":{"likeCount":0,"isLiked":false},"v2546d0b6cf13ebb000f6c23d7a8ae0e4b":{"likeCount":0,"isLiked":false},"v2559b93c1ffaae85d69bd53b0fadf75db":{"likeCount":4,"isLiked":false},"v25739a9eb93f7460352ca020b4a52d3c2":{"likeCount":1,"isLiked":false},"v267bd5a416910a98b278e90252dcfa426":{"likeCount":2,"isLiked":false},"v2Cbb05a284495c49d0a5f516621d04861":{"likeCount":0,"isLiked":false}}},"interactionBarPlugins":[{"type":"comment","comment":{"enable":true,"placeholder":"发条带图评论"}}],"barPluginsFlipTime":3000}},"columns":{"c_1363448145687584768":{"description":"","canManage":false,"intro":"笔记，整理，复盘","isFollowing":false,"urlToken":"c_1363448145687584768","id":"c_1363448145687584768","articlesCount":31,"acceptSubmission":false,"title":"关于算法工作的一些记录","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1363448145687584768","commentPermission":"all","created":1617851369,"updated":1704718581,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5.jpg?source=172ae18b","uid":"45037148700672","userType":"people","isFollowing":false,"urlToken":"lu-kai-14-46","id":"ba21f2a3b0e2f3b7fd2244cf6352cf2d","description":"","name":"流逝","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002Fba21f2a3b0e2f3b7fd2244cf6352cf2d","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002F3eed5e16176fbabd210a0bfa49ee68e5_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":0,"type":"column"},"c_1695749314725486593":{"description":"","canManage":false,"intro":"关于技术的学习与总结。","isFollowing":false,"urlToken":"c_1695749314725486593","id":"c_1695749314725486593","articlesCount":32,"acceptSubmission":false,"title":"计算机&通信技术","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1695749314725486593","commentPermission":"all","created":1697078142,"updated":1697078142,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-c86f0bffbbb4b0e0814bf0f2504689ac.jpg?source=172ae18b","uid":"918954495759773696","userType":"people","isFollowing":false,"urlToken":"zhy-72-18","id":"192c974c8b6ce0e0e358adf6e92a737b","description":"","name":"楚江南","isAdvertiser":false,"headline":"","gender":-1,"url":"\u002Fpeople\u002F192c974c8b6ce0e0e358adf6e92a737b","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-c86f0bffbbb4b0e0814bf0f2504689ac_l.jpg?source=172ae18b","isOrg":false,"type":"people","badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""}},"followers":0,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"zvideos":{},"zvideoContributions":{},"eduCourses":{}},"currentUser":"a70b9eb6781d764f023eb2a26684f261","account":{"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false},"cardUserInfo":{"vipInfo":{}},"handleWidget":{},"widgetList":[],"userWidgetId":""},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{},"infinity":{},"batchUsers":{},"profileInfinity":null},"env":{"abV2":{"config":{"paramMap":{"ws_must_login":{"value":"1","abId":"rl-must_login-1"},"ws_publish_post":{"value":"1","abId":"rl-publish_article-1"},"ws_platform_new":{"value":"1","abId":"author_platform-1"},"ws_is_show":{"value":"0"},"ws_video_publish":{"value":"1","abId":"rl-video_contentpub-1"},"pc_mou_cre_remove":{"value":"1","abId":"rl-mou_create_remove-1"},"ws_publish_answer":{"value":"1","abId":"rl-pc_pub_answer_2-1"},"ws_qiangzhisafe":{"value":"1","abId":"rl-qiangzhisafe_copy-1"},"ws_publish_ask":{"value":"1","abId":"rl-pc_publish_ask-1"}},"abMap":{"rl-must_login-1":{"abId":"rl-must_login-1","layerId":"rl-must_login"},"rl-publish_article-1":{"abId":"rl-publish_article-1","layerId":"rl-publish_article","diversionType":2},"author_platform-1":{"abId":"author_platform-1","layerId":"author_platform_layer","diversionType":2},"rl-video_contentpub-1":{"abId":"rl-video_contentpub-1","layerId":"rl-video_contentpub","diversionType":2},"rl-mou_create_remove-1":{"abId":"rl-mou_create_remove-1","layerId":"rl-mou_create_remove","diversionType":2},"rl-pc_pub_answer_2-1":{"abId":"rl-pc_pub_answer_2-1","layerId":"rl-pc_pub_answer_2","diversionType":2},"rl-qiangzhisafe_copy-1":{"abId":"rl-qiangzhisafe_copy-1","layerId":"rl-qiangzhisafe_copy"},"rl-pc_publish_ask-1":{"abId":"rl-pc_publish_ask-1","layerId":"rl-pc_publish_ask","diversionType":2}}},"triggers":{}},"userAgent":{"Edge":false,"IE":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"HarmonyOS":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Quark":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"WxMiniProgram":false,"BaiduMiniProgram":false,"QQMiniProgram":false,"JDMiniProgram":false,"isWebView":false,"isMiniProgram":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F126.0.0.0 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F670958880","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F670958880","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"beijing":false,"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false,"oppoSearch":false,"baiduSearch":false,"googleSearch":false,"shenma":false,"miniProgram":false,"xiaomi":false,"huaweiSearch":false},"theme":"light","appHeaderTheme":{"current":"normal","disable":true,"normal":{"bgColor":"GBK99A"},"custom":{"bgColor":"GBK99A"}},"enableShortcut":true,"referer":"","xUDId":"ANDeW9AlrRiPTh_Pislk-ZqJ8SgXtZowSNE=","mode":"ssr","conf":{},"xTrafficFreeOrigin":"","ipInfo":{"cityName":"中卫","countryName":"中国","regionName":"宁夏","countryCode":"CN"},"logged":true,"vars":{"passThroughHeaders":{}}},"me":{"columnContributions":[]},"label":{},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0}},"recommend":{"recommendTimes":{}}},"explore":{},"levelUpperLimit":10,"mcn":{},"mcnManage":{},"tasks":{},"announcement":{},"creatorsRecommendInfo":{}},"creators":{"common":{"applyStatus":{},"rightsStatus":{}},"bayesDomains":{"status":{},"options":{"topDomains":null,"allDomains":null,"editable":0},"contents":null},"school":{"tabs":[],"contents":[],"banner":null,"entities":{}},"faq":{"tabs":[],"article":{}},"knowledgeIncome":{},"safeguardRights":{},"analytics":{"all":{},"answer":{},"zvideo":{},"article":{},"pin":{},"singleContent":{}},"account":{"growthLevel":{}},"KMResource":{},"training":{},"ToolsQuestion":{"goodatTopics":[]},"ToolsHotspot":{"domains":[]},"ToolsRecommend":{},"ToolsCustomPromotion":{"itemLists":{},"baseInfo":{}},"ToolsSearchQuestion":{},"editorSetting":{},"MCNManage":{},"knowledgeTasks":{},"incomeAnalysis":{"income":{"aggregation":{}}},"creationManage":{"editModal":{"status":false}},"activity":{},"announcement":{},"home":{"currentCreatorUrlToken":null,"rights":[],"newRights":[],"scoreInfo":{},"menusShowControlByServer":{"bVipRecomend":false,"creationRelationship":false},"newTasks":{"creatorTask":{"tasks":[],"des":[]}},"bannerList":[],"recentlyCreated":[],"homecard":{},"homeData":{}},"videoSupport":{"textBenefit":{}},"videoDistribution":{},"profilePoster":{"creatorPosterConfig":{},"creatorPosterData":{}}},"answers":{"voters":{},"upvoters":{},"copyrightApplicants":{},"favlists":{},"newAnswer":{},"entityWords":{},"paidContent":{},"settings":{},"relationEndorsement":{},"interests":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{},"upvoters":{},"relationEndorsement":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotList":[],"hotListHeadZone":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]},"hotDaily":{"data":[],"paging":{}},"hotHighlight":{"isFetching":false,"isDrained":false,"data":[],"paging":{}},"banner":{},"commercialBanner":{"show":false,"banner":{},"trackData":{}},"video":{"items":[],"next":null,"isLoading":false,"isDrained":false}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"c_1363448145687584768","c_1695749314725486593"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[]},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"userProfit":{"permission":{"permissionStatus":{"zhiZixuan":0,"recommend":-1,"task":0,"plugin":0,"infinity":0},"visible":false},"linkCardLimit":0},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[],"lists":{},"banners":{},"protocolStatus":{"isAgreedNew":true,"isAgreedOld":true},"probationCountdownDays":0},"zvideos":{"campaignVideoList":{},"campaigns":{},"tagoreCategory":[],"recommendations":{},"insertable":{},"recruit":{"form":{"platform":"","nickname":"","followerCount":"","domain":"","contact":""},"submited":false,"ranking":[]},"qyActivityData":{},"talkActivityData":{},"party2022ActivityData":{},"batchVideos":{},"contribution":{"selectedContribution":null,"campaign":null,"configs":{},"contributionLists":{},"recommendQuestions":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]},"questionSearchResults":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]}},"creationReferences":{},"zvideoCollection":{},"zvideoGrant":{},"collectData":{"isFetching":false,"list":[]},"videoSource":{"isLoaded":false}},"republish":{},"commentPermission":{},"creatorRightStatus":{"list":[]},"adPromotion":{"answer":{},"article":{}}},"fetchHost":"www.zhihu.com","subAppName":"column","spanName":"Post","canaryConfig":{"test_canary":"0","use_new_player":"0","player_vendor":"0","use_hevc":"1","upload_use_signature":"1","use_backdrop_blur":"1","article_title_imagex":"1","play_station":"1","use_cached_supported_countries":"1"}}</script><script crossorigin="" src="https://static.zhihu.com/heifetz/vendor.b2043823c211547b094b.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react@17.0.2/umd/react.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/event/react-dom@17.0.2/umd/react-dom-server.browser.production.min.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/runtime.app.63a43987cf7ac5db392f.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-75fc9c18.app.3db651c252e14ef6658e.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-29107295.app.42d07f814b7b05187671.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-79b5cf47.app.8b6b6bf4b6d894db9b07.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-330004dc.app.7437cf54ac28fca0e302.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-f3572862.app.dd568f30e6619440400a.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-0e5ce61e.app.b22b78c2be57c983262f.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-83b0f42f.app.e34e650850a4762e3d73.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-38cf5c11.app.0ef475c02226ac0ff291.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-2ec050f6.app.3130baf54e01ef0a8956.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/lib-9b20c40c.app.5201d9d73d41de74d9b1.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/1907.app.c503fdd6a437b98e6497.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.app.5bbe156070826a8a790e.js"></script><script defer="" src="https://static.zhihu.com/event/wza/4613/aria.js?appid=a3637ace5dc3a347f6863b0bac487599" id="ariascripts" wapForceOldFixed="false" loadData="false"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script></html>